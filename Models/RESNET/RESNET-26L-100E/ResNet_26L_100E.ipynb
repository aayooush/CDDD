{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "7Di-zfmjqFis",
    "outputId": "a0762ec1-96e8-4024-bf23-b3bf1bc4a041"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive                \n",
    "drive.mount('/content/drive')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "id": "2vAiTJYspSRF",
    "outputId": "39d2f478-8a28-4f0c-dc81-9ae33c4792ca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Activation, BatchNormalization, Add, Input, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import Callback, LearningRateScheduler, TensorBoard\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import SVG\n",
    "import time\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ksJ4ijlpUQi"
   },
   "outputs": [],
   "source": [
    "class TimeHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_start_time = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j_lb5Ug_pUa4"
   },
   "outputs": [],
   "source": [
    "class ResNet:\n",
    "    def __init__(self, n, framework, channels_first=False, initial_lr=0.01, nb_epochs=100):\n",
    "        self.n = n\n",
    "        self.framework = framework\n",
    "        self.initial_lr = initial_lr\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.weight_decay = 0.0005\n",
    "        self.channels_first = channels_first\n",
    "        self.data_format = \"channels_first\" if channels_first else \"channels_last\"\n",
    "        self.bn_axis = 1 if channels_first else -1\n",
    "        # Make model\n",
    "        self.model = self.make_model()\n",
    "        plot_model(self.model, to_file='ResNet-26L-100E.png')\n",
    "#         SVG(model_to_dot(self.model).create(prog='dot', format='svg'))\n",
    "\n",
    "    def subsumpling(self, output_channels, input_tensor):\n",
    "        return Conv2D(output_channels, kernel_size=1, strides=(2,2), data_format=self.data_format, kernel_regularizer=l2(self.weight_decay))(input_tensor)\n",
    "\n",
    "    def block(self, channles, input_tensor):\n",
    "\n",
    "        shortcut = input_tensor\n",
    "        x = BatchNormalization(axis=self.bn_axis)(input_tensor)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2D(channles, kernel_size=3, padding=\"same\", data_format=self.data_format, kernel_regularizer=l2(self.weight_decay))(x)\n",
    "        x = BatchNormalization(axis=self.bn_axis)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2D(channles, kernel_size=3, padding=\"same\", data_format=self.data_format, kernel_regularizer=l2(self.weight_decay))(x)\n",
    "        return Add()([x, shortcut])\n",
    "\n",
    "    def make_model(self):\n",
    "        input = Input(shape=(3, 200, 200)) if self.channels_first else Input(shape=(200, 200, 3))\n",
    "        x = Conv2D(16, kernel_size=3, padding=\"same\", data_format=self.data_format, kernel_regularizer=l2(self.weight_decay))(input)\n",
    "        for i in range(self.n):\n",
    "            x = self.block(16, x)\n",
    "        # 16x16x32\n",
    "        x = self.subsumpling(32, x)\n",
    "        for i in range(self.n):\n",
    "            x = self.block(32, x)\n",
    "        # 8x8x64\n",
    "        x = self.subsumpling(64, x)\n",
    "        for i in range(self.n):\n",
    "            x = self.block(64, x)\n",
    "        # Global Average Pooling\n",
    "        x = GlobalAveragePooling2D(data_format=self.data_format)(x)\n",
    "        x = Dense(4, activation=\"softmax\")(x)\n",
    "        # model\n",
    "        model = Model(input, x)\n",
    "        return model\n",
    "\n",
    "    def lr_schduler(self, epoch):\n",
    "        x = self.initial_lr\n",
    "        if epoch >= self.nb_epochs * 0.5: x /= 10.0\n",
    "        if epoch >= self.nb_epochs * 0.75: x /= 10.0\n",
    "        return x\n",
    "\n",
    "    def train(self, TRAIN_PATH, VALIDATION_PATH):\n",
    "        self.model.summary()\n",
    "        self.model.compile(optimizer=SGD(lr=self.initial_lr, momentum=0.9), loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "        traingen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            width_shift_range=4./32,\n",
    "            height_shift_range=4./32,\n",
    "            horizontal_flip=True)\n",
    "        valgen = ImageDataGenerator(\n",
    "            rescale=1./255)\n",
    "        # Callback\n",
    "        time_cb = TimeHistory()\n",
    "        lr_cb = LearningRateScheduler(self.lr_schduler)\n",
    "        tensorboard = TensorBoard(log_dir=\"./logsRN-26L-100E/{}\".format(time.time()), \n",
    "                          histogram_freq=0, \n",
    "                          write_graph=True, \n",
    "                          write_grads=False, \n",
    "                          write_images=False, \n",
    "                          embeddings_freq=0, \n",
    "                          embeddings_layer_names=None, \n",
    "                          embeddings_metadata=None, \n",
    "                          embeddings_data=None, \n",
    "                          update_freq='epoch')\n",
    "\n",
    "        # Train\n",
    "        history = self.model.fit_generator(traingen.flow_from_directory(TRAIN_PATH, \n",
    "                                                                        target_size=(200,200),\n",
    "                                                                        class_mode='categorical'), \n",
    "                                           epochs=100,\n",
    "                                           callbacks=[time_cb, lr_cb, tensorboard],\n",
    "                                           validation_data = valgen.flow_from_directory( VALIDATION_PATH,\n",
    "                                                                                          target_size=(200,200),\n",
    "                                                                                          class_mode='categorical')).history\n",
    "        history[\"time\"] = time_cb.times\n",
    "        \n",
    "        \n",
    "        self.model.save(\"cotton_disease-resnet-26L-100E.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4DAOA1oJo_hj",
    "outputId": "391513a8-3443-4d56-b325-574da734eda5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 200, 200, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 200, 200, 16) 448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 200, 200, 16) 64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 200, 200, 16) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 200, 200, 16) 2320        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 200, 200, 16) 64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 200, 200, 16) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 200, 200, 16) 2320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 200, 200, 16) 0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 200, 200, 16) 64          add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 200, 200, 16) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 200, 200, 16) 2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 200, 200, 16) 64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 200, 200, 16) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 200, 200, 16) 2320        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 200, 200, 16) 0           conv2d_4[0][0]                   \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 200, 200, 16) 64          add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 200, 200, 16) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 200, 200, 16) 2320        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 200, 200, 16) 64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 200, 200, 16) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 200, 200, 16) 2320        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 200, 200, 16) 0           conv2d_6[0][0]                   \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 200, 200, 16) 64          add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 200, 200, 16) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 200, 200, 16) 2320        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 200, 200, 16) 64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 200, 200, 16) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 200, 200, 16) 2320        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 200, 200, 16) 0           conv2d_8[0][0]                   \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 100, 100, 32) 544         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 100, 100, 32) 128         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 100, 100, 32) 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 100, 100, 32) 9248        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 100, 100, 32) 128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 100, 100, 32) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 100, 100, 32) 9248        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 100, 100, 32) 0           conv2d_11[0][0]                  \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 100, 100, 32) 128         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 100, 100, 32) 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 100, 100, 32) 9248        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 100, 100, 32) 128         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 100, 100, 32) 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 100, 100, 32) 9248        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 100, 100, 32) 0           conv2d_13[0][0]                  \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 100, 100, 32) 128         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 100, 100, 32) 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 100, 100, 32) 9248        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 100, 100, 32) 128         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 100, 100, 32) 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 100, 100, 32) 9248        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 100, 100, 32) 0           conv2d_15[0][0]                  \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 100, 100, 32) 128         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 100, 100, 32) 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 100, 100, 32) 9248        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 100, 100, 32) 128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 100, 100, 32) 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 100, 100, 32) 9248        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 100, 100, 32) 0           conv2d_17[0][0]                  \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 50, 50, 64)   2112        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 50, 50, 64)   256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 50, 50, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 50, 50, 64)   36928       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 50, 50, 64)   256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 50, 50, 64)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 50, 50, 64)   36928       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 50, 50, 64)   0           conv2d_20[0][0]                  \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 50, 50, 64)   256         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 50, 50, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 50, 50, 64)   36928       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 50, 50, 64)   256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 50, 50, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 50, 50, 64)   36928       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 50, 50, 64)   0           conv2d_22[0][0]                  \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 50, 50, 64)   256         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 50, 50, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 50, 50, 64)   36928       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 50, 50, 64)   256         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 50, 50, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 50, 50, 64)   36928       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 50, 50, 64)   0           conv2d_24[0][0]                  \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 50, 50, 64)   256         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 50, 50, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 50, 50, 64)   36928       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 50, 50, 64)   256         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 50, 50, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 50, 50, 64)   36928       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 50, 50, 64)   0           conv2d_26[0][0]                  \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 64)           0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 4)            260         global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 394,916\n",
      "Trainable params: 393,124\n",
      "Non-trainable params: 1,792\n",
      "__________________________________________________________________________________________________\n",
      "Found 432 images belonging to 4 classes.\n",
      "Found 160 images belonging to 4 classes.\n",
      "Epoch 1/100\n",
      "13/14 [==========================>...] - ETA: 15s - loss: 2.1822 - acc: 0.5500Epoch 1/100\n",
      "14/14 [==============================] - 272s 19s/step - loss: 2.1848 - acc: 0.5301 - val_loss: 5.8006 - val_acc: 0.2500\n",
      "Epoch 2/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 2.8926 - acc: 0.4750Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 2.8612 - acc: 0.4861 - val_loss: 4.9228 - val_acc: 0.4313\n",
      "Epoch 3/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 3.8173 - acc: 0.4200Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 3.6840 - acc: 0.4352 - val_loss: 4.8616 - val_acc: 0.4313\n",
      "Epoch 4/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 2.7763 - acc: 0.5120Epoch 1/100\n",
      "14/14 [==============================] - 25s 2s/step - loss: 2.6836 - acc: 0.5139 - val_loss: 3.1749 - val_acc: 0.3688\n",
      "Epoch 5/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 2.0146 - acc: 0.5750Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 2.0341 - acc: 0.5741 - val_loss: 2.0909 - val_acc: 0.3688\n",
      "Epoch 6/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.6556 - acc: 0.6275Epoch 1/100\n",
      "14/14 [==============================] - 25s 2s/step - loss: 1.6449 - acc: 0.6319 - val_loss: 1.6190 - val_acc: 0.4938\n",
      "Epoch 7/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.4311 - acc: 0.7100Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.3988 - acc: 0.7176 - val_loss: 1.5178 - val_acc: 0.5750\n",
      "Epoch 8/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.2835 - acc: 0.7425Epoch 1/100\n",
      "14/14 [==============================] - 25s 2s/step - loss: 1.2693 - acc: 0.7454 - val_loss: 1.5224 - val_acc: 0.5250\n",
      "Epoch 9/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.3054 - acc: 0.7200Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.3237 - acc: 0.7222 - val_loss: 1.5402 - val_acc: 0.4938\n",
      "Epoch 10/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.3016 - acc: 0.7260Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.2855 - acc: 0.7199 - val_loss: 1.5442 - val_acc: 0.4875\n",
      "Epoch 11/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.1947 - acc: 0.7550Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.2042 - acc: 0.7639 - val_loss: 1.5469 - val_acc: 0.4875\n",
      "Epoch 12/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.1755 - acc: 0.7600Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.2064 - acc: 0.7593 - val_loss: 1.5365 - val_acc: 0.4938\n",
      "Epoch 13/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.1598 - acc: 0.7725Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.1666 - acc: 0.7662 - val_loss: 1.5135 - val_acc: 0.4938\n",
      "Epoch 14/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.1940 - acc: 0.7550Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.1838 - acc: 0.7569 - val_loss: 1.4929 - val_acc: 0.5000\n",
      "Epoch 15/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.1177 - acc: 0.7875Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.1091 - acc: 0.7847 - val_loss: 1.4699 - val_acc: 0.5250\n",
      "Epoch 16/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.1297 - acc: 0.7850Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.1302 - acc: 0.7847 - val_loss: 1.4467 - val_acc: 0.5375\n",
      "Epoch 17/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.1068 - acc: 0.7950Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.1083 - acc: 0.7847 - val_loss: 1.4212 - val_acc: 0.5562\n",
      "Epoch 18/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.0907 - acc: 0.7900Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.0772 - acc: 0.7963 - val_loss: 1.4110 - val_acc: 0.5625\n",
      "Epoch 19/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.1142 - acc: 0.7725Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.1342 - acc: 0.7778 - val_loss: 1.3889 - val_acc: 0.6062\n",
      "Epoch 20/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.1395 - acc: 0.7600Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.1438 - acc: 0.7731 - val_loss: 1.3573 - val_acc: 0.6313\n",
      "Epoch 21/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.0672 - acc: 0.8000Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.0627 - acc: 0.8009 - val_loss: 1.3145 - val_acc: 0.6500\n",
      "Epoch 22/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.0556 - acc: 0.8125Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.1060 - acc: 0.8056 - val_loss: 1.2935 - val_acc: 0.6687\n",
      "Epoch 23/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.0528 - acc: 0.8200Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.0585 - acc: 0.8102 - val_loss: 1.2945 - val_acc: 0.7188\n",
      "Epoch 24/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.0518 - acc: 0.8225Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.0631 - acc: 0.8148 - val_loss: 1.2743 - val_acc: 0.7125\n",
      "Epoch 25/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.0461 - acc: 0.8100Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.0496 - acc: 0.8125 - val_loss: 1.2269 - val_acc: 0.7125\n",
      "Epoch 26/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.0569 - acc: 0.8350Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.0637 - acc: 0.8310 - val_loss: 1.2305 - val_acc: 0.7688\n",
      "Epoch 27/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.0149 - acc: 0.8149Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.0070 - acc: 0.8171 - val_loss: 1.2282 - val_acc: 0.7750\n",
      "Epoch 28/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.0600 - acc: 0.8200Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.0507 - acc: 0.8194 - val_loss: 1.1676 - val_acc: 0.7688\n",
      "Epoch 29/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.0647 - acc: 0.7900Epoch 1/100\n",
      "14/14 [==============================] - 25s 2s/step - loss: 1.0542 - acc: 0.7940 - val_loss: 1.1546 - val_acc: 0.7875\n",
      "Epoch 30/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.0090 - acc: 0.8250Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.0077 - acc: 0.8264 - val_loss: 1.1743 - val_acc: 0.7875\n",
      "Epoch 31/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9911 - acc: 0.8250Epoch 1/100\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.9990 - acc: 0.8125 - val_loss: 1.1234 - val_acc: 0.7937\n",
      "Epoch 32/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9704 - acc: 0.8375Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.9576 - acc: 0.8449 - val_loss: 1.1075 - val_acc: 0.7875\n",
      "Epoch 33/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9829 - acc: 0.8375Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.9725 - acc: 0.8403 - val_loss: 1.0975 - val_acc: 0.8000\n",
      "Epoch 34/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9881 - acc: 0.8325Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.9854 - acc: 0.8333 - val_loss: 1.1149 - val_acc: 0.7937\n",
      "Epoch 35/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9657 - acc: 0.8250Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.9711 - acc: 0.8287 - val_loss: 1.0763 - val_acc: 0.8062\n",
      "Epoch 36/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.0054 - acc: 0.8200Epoch 1/100\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.9910 - acc: 0.8241 - val_loss: 1.0625 - val_acc: 0.8000\n",
      "Epoch 37/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.0059 - acc: 0.8175Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.9975 - acc: 0.8194 - val_loss: 1.0765 - val_acc: 0.8062\n",
      "Epoch 38/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9563 - acc: 0.8525Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.9578 - acc: 0.8519 - val_loss: 1.0740 - val_acc: 0.8000\n",
      "Epoch 39/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9926 - acc: 0.8050Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.9915 - acc: 0.8056 - val_loss: 1.1032 - val_acc: 0.7937\n",
      "Epoch 40/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9413 - acc: 0.8325Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.9588 - acc: 0.8218 - val_loss: 1.0582 - val_acc: 0.8000\n",
      "Epoch 41/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9466 - acc: 0.8425Epoch 1/100\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.9347 - acc: 0.8472 - val_loss: 1.0343 - val_acc: 0.8188\n",
      "Epoch 42/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9269 - acc: 0.8375Epoch 1/100\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.9330 - acc: 0.8356 - val_loss: 1.0310 - val_acc: 0.8125\n",
      "Epoch 43/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9475 - acc: 0.8200Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.9392 - acc: 0.8264 - val_loss: 1.0375 - val_acc: 0.8062\n",
      "Epoch 44/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9792 - acc: 0.8075Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.9722 - acc: 0.8079 - val_loss: 1.0343 - val_acc: 0.8062\n",
      "Epoch 45/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9039 - acc: 0.8400Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.9314 - acc: 0.8310 - val_loss: 1.0298 - val_acc: 0.8250\n",
      "Epoch 46/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9639 - acc: 0.8250Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.9513 - acc: 0.8310 - val_loss: 1.0133 - val_acc: 0.8250\n",
      "Epoch 47/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8961 - acc: 0.8350Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8952 - acc: 0.8356 - val_loss: 1.0106 - val_acc: 0.8438\n",
      "Epoch 48/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9668 - acc: 0.8350Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.9512 - acc: 0.8426 - val_loss: 1.0099 - val_acc: 0.8500\n",
      "Epoch 49/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9325 - acc: 0.8575Epoch 1/100\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.9313 - acc: 0.8542 - val_loss: 1.0376 - val_acc: 0.8188\n",
      "Epoch 50/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9147 - acc: 0.8600Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.9174 - acc: 0.8634 - val_loss: 0.9952 - val_acc: 0.8438\n",
      "Epoch 51/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9264 - acc: 0.8275Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.9314 - acc: 0.8241 - val_loss: 1.0059 - val_acc: 0.8438\n",
      "Epoch 52/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9366 - acc: 0.8225Epoch 1/100\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.9423 - acc: 0.8171 - val_loss: 1.0181 - val_acc: 0.8438\n",
      "Epoch 53/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9250 - acc: 0.8575Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.9199 - acc: 0.8657 - val_loss: 1.0498 - val_acc: 0.8125\n",
      "Epoch 54/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9139 - acc: 0.8350Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.9186 - acc: 0.8310 - val_loss: 1.0316 - val_acc: 0.8188\n",
      "Epoch 55/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9701 - acc: 0.8050Epoch 1/100\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.9584 - acc: 0.8125 - val_loss: 0.9988 - val_acc: 0.8500\n",
      "Epoch 56/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9223 - acc: 0.8400Epoch 1/100\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.9279 - acc: 0.8380 - val_loss: 1.0088 - val_acc: 0.8438\n",
      "Epoch 57/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8891 - acc: 0.8450Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8860 - acc: 0.8449 - val_loss: 1.0143 - val_acc: 0.8313\n",
      "Epoch 58/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9386 - acc: 0.8425Epoch 1/100\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.9446 - acc: 0.8449 - val_loss: 0.9775 - val_acc: 0.8438\n",
      "Epoch 59/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9042 - acc: 0.8475Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.9234 - acc: 0.8333 - val_loss: 0.9781 - val_acc: 0.8500\n",
      "Epoch 60/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8967 - acc: 0.8450Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8993 - acc: 0.8472 - val_loss: 0.9750 - val_acc: 0.8500\n",
      "Epoch 61/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8946 - acc: 0.8425Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8897 - acc: 0.8449 - val_loss: 0.9926 - val_acc: 0.8250\n",
      "Epoch 62/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8787 - acc: 0.8350Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8828 - acc: 0.8310 - val_loss: 1.0042 - val_acc: 0.8125\n",
      "Epoch 63/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9271 - acc: 0.8413Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.9130 - acc: 0.8449 - val_loss: 0.9735 - val_acc: 0.8500\n",
      "Epoch 64/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9327 - acc: 0.8275Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.9296 - acc: 0.8287 - val_loss: 0.9672 - val_acc: 0.8562\n",
      "Epoch 65/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8815 - acc: 0.8425Epoch 1/100\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.8843 - acc: 0.8449 - val_loss: 0.9622 - val_acc: 0.8562\n",
      "Epoch 66/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9122 - acc: 0.8400Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.9384 - acc: 0.8241 - val_loss: 0.9672 - val_acc: 0.8375\n",
      "Epoch 67/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9073 - acc: 0.8350Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.9123 - acc: 0.8333 - val_loss: 0.9829 - val_acc: 0.8125\n",
      "Epoch 68/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8867 - acc: 0.8650Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8984 - acc: 0.8611 - val_loss: 1.0018 - val_acc: 0.8062\n",
      "Epoch 69/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8946 - acc: 0.8475Epoch 1/100\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.8853 - acc: 0.8542 - val_loss: 1.0023 - val_acc: 0.8062\n",
      "Epoch 70/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8964 - acc: 0.8365Epoch 1/100\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.9007 - acc: 0.8380 - val_loss: 0.9745 - val_acc: 0.8375\n",
      "Epoch 71/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8952 - acc: 0.8600Epoch 1/100\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.9078 - acc: 0.8449 - val_loss: 0.9698 - val_acc: 0.8375\n",
      "Epoch 72/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9180 - acc: 0.8475Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.9084 - acc: 0.8495 - val_loss: 0.9462 - val_acc: 0.8438\n",
      "Epoch 73/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8606 - acc: 0.8475Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8708 - acc: 0.8403 - val_loss: 0.9634 - val_acc: 0.8375\n",
      "Epoch 74/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8882 - acc: 0.8400Epoch 1/100\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.8877 - acc: 0.8449 - val_loss: 0.9814 - val_acc: 0.8250\n",
      "Epoch 75/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9398 - acc: 0.8350Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.9286 - acc: 0.8426 - val_loss: 0.9876 - val_acc: 0.8062\n",
      "Epoch 76/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8763 - acc: 0.8725Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8787 - acc: 0.8704 - val_loss: 0.9431 - val_acc: 0.8438\n",
      "Epoch 77/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8814 - acc: 0.8575Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8777 - acc: 0.8634 - val_loss: 0.9475 - val_acc: 0.8500\n",
      "Epoch 78/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8490 - acc: 0.8725Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8493 - acc: 0.8727 - val_loss: 0.9483 - val_acc: 0.8438\n",
      "Epoch 79/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8486 - acc: 0.8750Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8513 - acc: 0.8750 - val_loss: 0.9517 - val_acc: 0.8562\n",
      "Epoch 80/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8812 - acc: 0.8500Epoch 1/100\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.8719 - acc: 0.8542 - val_loss: 0.9661 - val_acc: 0.8250\n",
      "Epoch 81/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8704 - acc: 0.8525Epoch 1/100\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.8679 - acc: 0.8519 - val_loss: 0.9610 - val_acc: 0.8250\n",
      "Epoch 82/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8486 - acc: 0.8675Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8647 - acc: 0.8634 - val_loss: 0.9710 - val_acc: 0.8125\n",
      "Epoch 83/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8660 - acc: 0.8750Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8704 - acc: 0.8727 - val_loss: 0.9320 - val_acc: 0.8500\n",
      "Epoch 84/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8762 - acc: 0.8600Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8696 - acc: 0.8657 - val_loss: 0.9387 - val_acc: 0.8500\n",
      "Epoch 85/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8820 - acc: 0.8400Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8738 - acc: 0.8449 - val_loss: 0.9457 - val_acc: 0.8438\n",
      "Epoch 86/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8693 - acc: 0.8700Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8646 - acc: 0.8704 - val_loss: 0.9385 - val_acc: 0.8438\n",
      "Epoch 87/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8967 - acc: 0.8600Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8775 - acc: 0.8681 - val_loss: 0.9340 - val_acc: 0.8375\n",
      "Epoch 88/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8551 - acc: 0.8800Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8519 - acc: 0.8773 - val_loss: 0.9245 - val_acc: 0.8500\n",
      "Epoch 89/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8339 - acc: 0.8800Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8527 - acc: 0.8727 - val_loss: 0.9388 - val_acc: 0.8500\n",
      "Epoch 90/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8535 - acc: 0.8500Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8560 - acc: 0.8472 - val_loss: 0.9962 - val_acc: 0.8000\n",
      "Epoch 91/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8885 - acc: 0.8700Epoch 1/100\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.8916 - acc: 0.8681 - val_loss: 0.9286 - val_acc: 0.8500\n",
      "Epoch 92/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8852 - acc: 0.8675Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8813 - acc: 0.8657 - val_loss: 0.9186 - val_acc: 0.8500\n",
      "Epoch 93/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8594 - acc: 0.8500Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8552 - acc: 0.8565 - val_loss: 0.9273 - val_acc: 0.8500\n",
      "Epoch 94/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8633 - acc: 0.8425Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8594 - acc: 0.8403 - val_loss: 0.9425 - val_acc: 0.8500\n",
      "Epoch 95/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8796 - acc: 0.8575Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8747 - acc: 0.8588 - val_loss: 0.9157 - val_acc: 0.8562\n",
      "Epoch 96/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8717 - acc: 0.8575Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8721 - acc: 0.8542 - val_loss: 0.9092 - val_acc: 0.8625\n",
      "Epoch 97/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8690 - acc: 0.8500Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8593 - acc: 0.8542 - val_loss: 0.9039 - val_acc: 0.8625\n",
      "Epoch 98/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8409 - acc: 0.8600Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8372 - acc: 0.8657 - val_loss: 0.8958 - val_acc: 0.8750\n",
      "Epoch 99/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8583 - acc: 0.8750Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8527 - acc: 0.8750 - val_loss: 0.9097 - val_acc: 0.8500\n",
      "Epoch 100/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8578 - acc: 0.8575Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8546 - acc: 0.8634 - val_loss: 0.9115 - val_acc: 0.8562\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Main function\n",
    "def main(n, framework):\n",
    "    # layers = 6n+2\n",
    "    net = ResNet(n, framework, nb_epochs=1)\n",
    "    base_dir = '/content/drive/My Drive/B.E PROJECT/CNN CROP/data/disease/input'\n",
    "\n",
    "    TRAIN_PATH = os.path.join(base_dir, 'Training')\n",
    "    VALIDATION_PATH = os.path.join(base_dir, 'Validation')\n",
    "    net.train(TRAIN_PATH, VALIDATION_PATH)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(4, \"keras_tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "RsyPc3-ir8YW",
    "outputId": "36170639-1952-4b31-dbc0-5586e4bafc1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cotton_disease-resnet50E44L.h5  'logsRN-3(100E 44L)'   sample_data\n",
      " drive\t\t\t\t  ResNet.png\n"
     ]
    }
   ],
   "source": [
    "  !ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "8cnyYNFOS3rF",
    "outputId": "4675ab6f-f9a1-471c-c8ad-82301eb1f149"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: content/logsRN-26L-100E/ (stored 0%)\n",
      "updating: content/logsRN-26L-100E/1572362515.5789483/ (stored 0%)\n",
      "updating: content/logsRN-26L-100E/1572362515.5789483/plugins/ (stored 0%)\n",
      "updating: content/logsRN-26L-100E/1572362515.5789483/plugins/profile/ (stored 0%)\n",
      "updating: content/logsRN-26L-100E/1572362515.5789483/plugins/profile/2019-10-29_15-22-43/ (stored 0%)\n",
      "updating: content/logsRN-26L-100E/1572362515.5789483/plugins/profile/2019-10-29_15-22-43/local.trace (deflated 96%)\n",
      "updating: content/logsRN-26L-100E/1572362515.5789483/events.out.tfevents.1572362518.34f4422ef852 (deflated 92%)\n",
      "updating: content/logsRN-26L-100E/1572362515.5789483/events.out.tfevents.1572362563.34f4422ef852.profile-empty (deflated 5%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r \"/content/resnet26L100E.zip\" \"/content/logsRN-26L-100E/\"\n",
    "from google.colab import files\n",
    "files.download(\"/content/resnet26L100E.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OaqTtxb7S9lY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ResNet-26L-100E.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
