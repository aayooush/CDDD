{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet-44L-50E.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Di-zfmjqFis",
        "colab_type": "code",
        "outputId": "bff46dd7-aeb6-4895-cded-84b4cf1cd3ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive                \n",
        "drive.mount('/content/drive')   "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vAiTJYspSRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, Activation, BatchNormalization, Add, Input, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import Callback, LearningRateScheduler, TensorBoard\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "import time\n",
        "import pickle\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ksJ4ijlpUQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TimeHistory(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.times = []\n",
        "\n",
        "    def on_epoch_begin(self, batch, logs={}):\n",
        "        self.epoch_start_time = time.time()\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        self.times.append(time.time() - self.epoch_start_time)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_lb5Ug_pUa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet:\n",
        "    def __init__(self, n, framework, channels_first=False, initial_lr=0.01, nb_epochs=100):\n",
        "        self.n = n\n",
        "        self.framework = framework\n",
        "        self.initial_lr = initial_lr\n",
        "        self.nb_epochs = nb_epochs\n",
        "        self.weight_decay = 0.0005\n",
        "        self.channels_first = channels_first\n",
        "        self.data_format = \"channels_first\" if channels_first else \"channels_last\"\n",
        "        self.bn_axis = 1 if channels_first else -1\n",
        "        # Make model\n",
        "        self.model = self.make_model()\n",
        "        plot_model(self.model, to_file='ResNet-44L-50E.png')\n",
        "#         SVG(model_to_dot(self.model).create(prog='dot', format='svg'))\n",
        "\n",
        "    def subsumpling(self, output_channels, input_tensor):\n",
        "        return Conv2D(output_channels, kernel_size=1, strides=(2,2), data_format=self.data_format, kernel_regularizer=l2(self.weight_decay))(input_tensor)\n",
        "\n",
        "    def block(self, channles, input_tensor):\n",
        "\n",
        "        shortcut = input_tensor\n",
        "        x = BatchNormalization(axis=self.bn_axis)(input_tensor)\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = Conv2D(channles, kernel_size=3, padding=\"same\", data_format=self.data_format, kernel_regularizer=l2(self.weight_decay))(x)\n",
        "        x = BatchNormalization(axis=self.bn_axis)(x)\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = Conv2D(channles, kernel_size=3, padding=\"same\", data_format=self.data_format, kernel_regularizer=l2(self.weight_decay))(x)\n",
        "        return Add()([x, shortcut])\n",
        "\n",
        "    def make_model(self):\n",
        "        input = Input(shape=(3, 200, 200)) if self.channels_first else Input(shape=(200, 200, 3))\n",
        "        x = Conv2D(16, kernel_size=3, padding=\"same\", data_format=self.data_format, kernel_regularizer=l2(self.weight_decay))(input)\n",
        "        for i in range(self.n):\n",
        "            x = self.block(16, x)\n",
        "        # 16x16x32\n",
        "        x = self.subsumpling(32, x)\n",
        "        for i in range(self.n):\n",
        "            x = self.block(32, x)\n",
        "        # 8x8x64\n",
        "        x = self.subsumpling(64, x)\n",
        "        for i in range(self.n):\n",
        "            x = self.block(64, x)\n",
        "        # Global Average Pooling\n",
        "        x = GlobalAveragePooling2D(data_format=self.data_format)(x)\n",
        "        x = Dense(4, activation=\"softmax\")(x)\n",
        "        # model\n",
        "        model = Model(input, x)\n",
        "        return model\n",
        "\n",
        "    def lr_schduler(self, epoch):\n",
        "        x = self.initial_lr\n",
        "        if epoch >= self.nb_epochs * 0.5: x /= 10.0\n",
        "        if epoch >= self.nb_epochs * 0.75: x /= 5.0\n",
        "        return x\n",
        "\n",
        "    def train(self, TRAIN_PATH, VALIDATION_PATH):\n",
        "        self.model.summary()\n",
        "        self.model.compile(optimizer=SGD(lr=self.initial_lr, momentum=0.9), loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
        "        traingen = ImageDataGenerator(\n",
        "            rescale=1./255,\n",
        "            width_shift_range=4./32,\n",
        "            height_shift_range=4./32,\n",
        "            horizontal_flip=True)\n",
        "        valgen = ImageDataGenerator(\n",
        "            rescale=1./255)\n",
        "        # Callback\n",
        "        time_cb = TimeHistory()\n",
        "        lr_cb = LearningRateScheduler(self.lr_schduler)\n",
        "        tensorboard = TensorBoard(log_dir=\"./logsRN-44L-50E/{}\".format(time.time()), \n",
        "                          histogram_freq=0, \n",
        "                          write_graph=True, \n",
        "                          write_grads=False, \n",
        "                          write_images=False, \n",
        "                          embeddings_freq=0, \n",
        "                          embeddings_layer_names=None, \n",
        "                          embeddings_metadata=None, \n",
        "                          embeddings_data=None, \n",
        "                          update_freq='epoch')\n",
        "\n",
        "        # Train\n",
        "        history = self.model.fit_generator(traingen.flow_from_directory(TRAIN_PATH, \n",
        "                                                                        target_size=(200,200),\n",
        "                                                                        class_mode='categorical'), \n",
        "                                           epochs=50,\n",
        "                                           callbacks=[time_cb, lr_cb, tensorboard],\n",
        "                                           validation_data = valgen.flow_from_directory( VALIDATION_PATH,\n",
        "                                                                                          target_size=(200,200),\n",
        "                                                                                          class_mode='categorical')).history\n",
        "        history[\"time\"] = time_cb.times\n",
        "        \n",
        "        \n",
        "        self.model.save(\"cotton_disease-ResNet-44L-50E.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DAOA1oJo_hj",
        "colab_type": "code",
        "outputId": "5e587ed9-ba16-4e56-e3d9-43b32dd8c2b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# Main function\n",
        "def main(n, framework):\n",
        "    # layers = 6n+2\n",
        "    net = ResNet(n, framework, nb_epochs=1)\n",
        "    base_dir = '/content/drive/My Drive/B.E PROJECT/CNN CROP/data/disease/input'\n",
        "\n",
        "    TRAIN_PATH = os.path.join(base_dir, 'Training')\n",
        "    VALIDATION_PATH = os.path.join(base_dir, 'Validation')\n",
        "    net.train(TRAIN_PATH, VALIDATION_PATH)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main(6, \"keras_tf\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 200, 200, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 200, 200, 16) 448         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 200, 200, 16) 64          conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 200, 200, 16) 0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 200, 200, 16) 2320        activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 200, 200, 16) 64          conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 200, 200, 16) 0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 200, 200, 16) 2320        activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 200, 200, 16) 0           conv2d_41[0][0]                  \n",
            "                                                                 conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 200, 200, 16) 64          add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 200, 200, 16) 0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 200, 200, 16) 2320        activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 200, 200, 16) 64          conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 200, 200, 16) 0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 200, 200, 16) 2320        activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 200, 200, 16) 0           conv2d_43[0][0]                  \n",
            "                                                                 add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 200, 200, 16) 64          add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 200, 200, 16) 0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 200, 200, 16) 2320        activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 200, 200, 16) 64          conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 200, 200, 16) 0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 200, 200, 16) 2320        activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 200, 200, 16) 0           conv2d_45[0][0]                  \n",
            "                                                                 add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 200, 200, 16) 64          add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 200, 200, 16) 0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 200, 200, 16) 2320        activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 200, 200, 16) 64          conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 200, 200, 16) 0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 200, 200, 16) 2320        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 200, 200, 16) 0           conv2d_47[0][0]                  \n",
            "                                                                 add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 200, 200, 16) 64          add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 200, 200, 16) 0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 200, 200, 16) 2320        activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 200, 200, 16) 64          conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 200, 200, 16) 0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 200, 200, 16) 2320        activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 200, 200, 16) 0           conv2d_49[0][0]                  \n",
            "                                                                 add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 200, 200, 16) 64          add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 200, 200, 16) 0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 200, 200, 16) 2320        activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 200, 200, 16) 64          conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 200, 200, 16) 0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 200, 200, 16) 2320        activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 200, 200, 16) 0           conv2d_51[0][0]                  \n",
            "                                                                 add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 100, 100, 32) 544         add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 100, 100, 32) 128         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 100, 100, 32) 0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 100, 100, 32) 9248        activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 100, 100, 32) 128         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 100, 100, 32) 0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 100, 100, 32) 9248        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 100, 100, 32) 0           conv2d_54[0][0]                  \n",
            "                                                                 conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 100, 100, 32) 128         add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 100, 100, 32) 0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 100, 100, 32) 9248        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 100, 100, 32) 128         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 100, 100, 32) 0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 100, 100, 32) 9248        activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 100, 100, 32) 0           conv2d_56[0][0]                  \n",
            "                                                                 add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 100, 100, 32) 128         add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 100, 100, 32) 0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 100, 100, 32) 9248        activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 100, 100, 32) 128         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 100, 100, 32) 0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 100, 100, 32) 9248        activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 100, 100, 32) 0           conv2d_58[0][0]                  \n",
            "                                                                 add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 100, 100, 32) 128         add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 100, 100, 32) 0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 100, 100, 32) 9248        activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 100, 100, 32) 128         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 100, 100, 32) 0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 100, 100, 32) 9248        activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 100, 100, 32) 0           conv2d_60[0][0]                  \n",
            "                                                                 add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 100, 100, 32) 128         add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 100, 100, 32) 0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 100, 100, 32) 9248        activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 100, 100, 32) 128         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 100, 100, 32) 0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 100, 100, 32) 9248        activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 100, 100, 32) 0           conv2d_62[0][0]                  \n",
            "                                                                 add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 100, 100, 32) 128         add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 100, 100, 32) 0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 100, 100, 32) 9248        activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 100, 100, 32) 128         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 100, 100, 32) 0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 100, 100, 32) 9248        activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 100, 100, 32) 0           conv2d_64[0][0]                  \n",
            "                                                                 add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 50, 50, 64)   2112        add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 50, 50, 64)   256         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 50, 50, 64)   0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 50, 50, 64)   36928       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 50, 50, 64)   256         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 50, 50, 64)   0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 50, 50, 64)   36928       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 50, 50, 64)   0           conv2d_67[0][0]                  \n",
            "                                                                 conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 50, 50, 64)   256         add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 50, 50, 64)   0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 50, 50, 64)   36928       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 50, 50, 64)   256         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 50, 50, 64)   0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 50, 50, 64)   36928       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 50, 50, 64)   0           conv2d_69[0][0]                  \n",
            "                                                                 add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 50, 50, 64)   256         add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 50, 50, 64)   0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 50, 50, 64)   36928       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 50, 50, 64)   256         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 50, 50, 64)   0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 50, 50, 64)   36928       activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 50, 50, 64)   0           conv2d_71[0][0]                  \n",
            "                                                                 add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 50, 50, 64)   256         add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 50, 50, 64)   0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 50, 50, 64)   36928       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 50, 50, 64)   256         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 50, 50, 64)   0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 50, 50, 64)   36928       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 50, 50, 64)   0           conv2d_73[0][0]                  \n",
            "                                                                 add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 50, 50, 64)   256         add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 50, 50, 64)   0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 50, 50, 64)   36928       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 50, 50, 64)   256         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 50, 50, 64)   0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 50, 50, 64)   36928       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 50, 50, 64)   0           conv2d_75[0][0]                  \n",
            "                                                                 add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 50, 50, 64)   256         add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 50, 50, 64)   0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 50, 50, 64)   36928       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 50, 50, 64)   256         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 50, 50, 64)   0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 50, 50, 64)   36928       activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 50, 50, 64)   0           conv2d_77[0][0]                  \n",
            "                                                                 add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 64)           0           add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 4)            260         global_average_pooling2d_1[0][0] \n",
            "==================================================================================================\n",
            "Total params: 590,692\n",
            "Trainable params: 588,004\n",
            "Non-trainable params: 2,688\n",
            "__________________________________________________________________________________________________\n",
            "Found 432 images belonging to 4 classes.\n",
            "Found 160 images belonging to 4 classes.\n",
            "Epoch 1/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 2.6467 - acc: 0.5250Epoch 1/50\n",
            "14/14 [==============================] - 40s 3s/step - loss: 2.6669 - acc: 0.5347 - val_loss: 34.1472 - val_acc: 0.2500\n",
            "Epoch 2/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 5.7902 - acc: 0.3975Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 5.6857 - acc: 0.3889 - val_loss: 120.5868 - val_acc: 0.2500\n",
            "Epoch 3/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 4.0265 - acc: 0.4050Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 3.8426 - acc: 0.4213 - val_loss: 22.7624 - val_acc: 0.3438\n",
            "Epoch 4/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 2.4507 - acc: 0.5650Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 2.3628 - acc: 0.5787 - val_loss: 5.0020 - val_acc: 0.4375\n",
            "Epoch 5/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.8374 - acc: 0.7000Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.8355 - acc: 0.6968 - val_loss: 3.5619 - val_acc: 0.2688\n",
            "Epoch 6/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.5630 - acc: 0.7300Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.5593 - acc: 0.7292 - val_loss: 4.8866 - val_acc: 0.2500\n",
            "Epoch 7/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.4465 - acc: 0.7500Epoch 1/50\n",
            "14/14 [==============================] - 32s 2s/step - loss: 1.4417 - acc: 0.7546 - val_loss: 5.1331 - val_acc: 0.2500\n",
            "Epoch 8/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.3861 - acc: 0.7700Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.3906 - acc: 0.7616 - val_loss: 4.8726 - val_acc: 0.2500\n",
            "Epoch 9/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.3585 - acc: 0.7625Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.3353 - acc: 0.7708 - val_loss: 4.5440 - val_acc: 0.2500\n",
            "Epoch 10/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.3181 - acc: 0.7600Epoch 1/50\n",
            "14/14 [==============================] - 32s 2s/step - loss: 1.3017 - acc: 0.7708 - val_loss: 4.1016 - val_acc: 0.2500\n",
            "Epoch 11/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.2711 - acc: 0.7850Epoch 1/50\n",
            "14/14 [==============================] - 32s 2s/step - loss: 1.2614 - acc: 0.7894 - val_loss: 3.8788 - val_acc: 0.2562\n",
            "Epoch 12/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.3011 - acc: 0.7900Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.2888 - acc: 0.8009 - val_loss: 3.7485 - val_acc: 0.3000\n",
            "Epoch 13/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.2205 - acc: 0.8050Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.2225 - acc: 0.8032 - val_loss: 3.4736 - val_acc: 0.3375\n",
            "Epoch 14/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.2276 - acc: 0.8075Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.2357 - acc: 0.8079 - val_loss: 3.3868 - val_acc: 0.3438\n",
            "Epoch 15/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.2350 - acc: 0.8175Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.2344 - acc: 0.8218 - val_loss: 3.1376 - val_acc: 0.3688\n",
            "Epoch 16/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.2091 - acc: 0.8050Epoch 1/50\n",
            "14/14 [==============================] - 32s 2s/step - loss: 1.2085 - acc: 0.8009 - val_loss: 3.0223 - val_acc: 0.3875\n",
            "Epoch 17/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.2074 - acc: 0.8173Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.2013 - acc: 0.8194 - val_loss: 2.8896 - val_acc: 0.4125\n",
            "Epoch 18/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.2305 - acc: 0.8225Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.2258 - acc: 0.8241 - val_loss: 2.7757 - val_acc: 0.4125\n",
            "Epoch 19/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.1747 - acc: 0.8400Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.1922 - acc: 0.8333 - val_loss: 2.5904 - val_acc: 0.4563\n",
            "Epoch 20/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.1401 - acc: 0.8425Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.1422 - acc: 0.8380 - val_loss: 2.4873 - val_acc: 0.4563\n",
            "Epoch 21/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.1598 - acc: 0.8450Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.1510 - acc: 0.8472 - val_loss: 2.3980 - val_acc: 0.4625\n",
            "Epoch 22/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.1334 - acc: 0.8425Epoch 1/50\n",
            "14/14 [==============================] - 32s 2s/step - loss: 1.1258 - acc: 0.8472 - val_loss: 2.3022 - val_acc: 0.4938\n",
            "Epoch 23/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.1069 - acc: 0.8750Epoch 1/50\n",
            "14/14 [==============================] - 32s 2s/step - loss: 1.1118 - acc: 0.8750 - val_loss: 2.1683 - val_acc: 0.4938\n",
            "Epoch 24/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.1275 - acc: 0.8450Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.1230 - acc: 0.8472 - val_loss: 2.0866 - val_acc: 0.5250\n",
            "Epoch 25/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.1554 - acc: 0.8400Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.1608 - acc: 0.8356 - val_loss: 1.9955 - val_acc: 0.5375\n",
            "Epoch 26/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.1508 - acc: 0.8375Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.1402 - acc: 0.8403 - val_loss: 1.7928 - val_acc: 0.5688\n",
            "Epoch 27/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.1262 - acc: 0.8525Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.1250 - acc: 0.8542 - val_loss: 1.6579 - val_acc: 0.6062\n",
            "Epoch 28/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.1314 - acc: 0.8675Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.1436 - acc: 0.8657 - val_loss: 1.6371 - val_acc: 0.6187\n",
            "Epoch 29/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.1057 - acc: 0.8475Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.1008 - acc: 0.8519 - val_loss: 1.5958 - val_acc: 0.6438\n",
            "Epoch 30/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.1296 - acc: 0.8275Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.1210 - acc: 0.8310 - val_loss: 1.4707 - val_acc: 0.6625\n",
            "Epoch 31/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.0792 - acc: 0.8625Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.0985 - acc: 0.8611 - val_loss: 1.3779 - val_acc: 0.7500\n",
            "Epoch 32/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.1173 - acc: 0.8600Epoch 1/50\n",
            "14/14 [==============================] - 32s 2s/step - loss: 1.1071 - acc: 0.8657 - val_loss: 1.3413 - val_acc: 0.7312\n",
            "Epoch 33/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.1419 - acc: 0.8250Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.1462 - acc: 0.8194 - val_loss: 1.3461 - val_acc: 0.7312\n",
            "Epoch 34/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.0964 - acc: 0.8675Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.0855 - acc: 0.8727 - val_loss: 1.2608 - val_acc: 0.8000\n",
            "Epoch 35/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.1002 - acc: 0.8575Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.1004 - acc: 0.8588 - val_loss: 1.2244 - val_acc: 0.8062\n",
            "Epoch 36/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.1015 - acc: 0.8450Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.0999 - acc: 0.8472 - val_loss: 1.2014 - val_acc: 0.8062\n",
            "Epoch 37/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.1399 - acc: 0.8400Epoch 1/50\n",
            "14/14 [==============================] - 32s 2s/step - loss: 1.1331 - acc: 0.8426 - val_loss: 1.1717 - val_acc: 0.8188\n",
            "Epoch 38/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.0959 - acc: 0.8675Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.0939 - acc: 0.8634 - val_loss: 1.1829 - val_acc: 0.8000\n",
            "Epoch 39/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.0402 - acc: 0.8850Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.0542 - acc: 0.8773 - val_loss: 1.1558 - val_acc: 0.8188\n",
            "Epoch 40/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.1056 - acc: 0.8625Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.0959 - acc: 0.8588 - val_loss: 1.1811 - val_acc: 0.8188\n",
            "Epoch 41/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.0880 - acc: 0.8575Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.0798 - acc: 0.8657 - val_loss: 1.1353 - val_acc: 0.8375\n",
            "Epoch 42/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.1593 - acc: 0.8375Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.1498 - acc: 0.8449 - val_loss: 1.1310 - val_acc: 0.8438\n",
            "Epoch 43/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.0648 - acc: 0.8625Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.0859 - acc: 0.8542 - val_loss: 1.1252 - val_acc: 0.8375\n",
            "Epoch 44/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.0498 - acc: 0.8774Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.0645 - acc: 0.8750 - val_loss: 1.1548 - val_acc: 0.8250\n",
            "Epoch 45/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.0562 - acc: 0.8650Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.0680 - acc: 0.8634 - val_loss: 1.1286 - val_acc: 0.8625\n",
            "Epoch 46/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.0663 - acc: 0.8650Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.0580 - acc: 0.8727 - val_loss: 1.1268 - val_acc: 0.8438\n",
            "Epoch 47/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.0580 - acc: 0.8600Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.0601 - acc: 0.8611 - val_loss: 1.2279 - val_acc: 0.8062\n",
            "Epoch 48/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.0748 - acc: 0.8525Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.0673 - acc: 0.8542 - val_loss: 1.1729 - val_acc: 0.8125\n",
            "Epoch 49/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.0364 - acc: 0.8700Epoch 1/50\n",
            "14/14 [==============================] - 32s 2s/step - loss: 1.0231 - acc: 0.8773 - val_loss: 1.1226 - val_acc: 0.8375\n",
            "Epoch 50/50\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.0446 - acc: 0.8550Epoch 1/50\n",
            "14/14 [==============================] - 31s 2s/step - loss: 1.0510 - acc: 0.8495 - val_loss: 1.1644 - val_acc: 0.8375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsyPc3-ir8YW",
        "colab_type": "code",
        "outputId": "36170639-1952-4b31-dbc0-5586e4bafc1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "  !ls "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " cotton_disease-resnet50E44L.h5  'logsRN-3(100E 44L)'   sample_data\n",
            " drive\t\t\t\t  ResNet.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cnyYNFOS3rF",
        "colab_type": "code",
        "outputId": "e63cc3da-52ca-402a-f4e7-664278d36730",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "!zip -r \"/content/ResNet-44L-50E.zip\" \"/content/logsRN-44L-50E/\"\n",
        "from google.colab import files\n",
        "files.download(\"/content/ResNet-44L-50E.zip\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/logsRN-44L-50E/ (stored 0%)\n",
            "  adding: content/logsRN-44L-50E/1572366643.379085/ (stored 0%)\n",
            "  adding: content/logsRN-44L-50E/1572366643.379085/plugins/ (stored 0%)\n",
            "  adding: content/logsRN-44L-50E/1572366643.379085/plugins/profile/ (stored 0%)\n",
            "  adding: content/logsRN-44L-50E/1572366643.379085/plugins/profile/2019-10-29_16-30-58/ (stored 0%)\n",
            "  adding: content/logsRN-44L-50E/1572366643.379085/plugins/profile/2019-10-29_16-30-58/local.trace (deflated 96%)\n",
            "  adding: content/logsRN-44L-50E/1572366643.379085/events.out.tfevents.1572366644.e52d0a16bf3c (deflated 93%)\n",
            "  adding: content/logsRN-44L-50E/1572366643.379085/events.out.tfevents.1572366658.e52d0a16bf3c.profile-empty (deflated 5%)\n",
            "  adding: content/logsRN-44L-50E/1572364491.2424731/ (stored 0%)\n",
            "  adding: content/logsRN-44L-50E/1572364491.2424731/events.out.tfevents.1572364556.e52d0a16bf3c.profile-empty (deflated 10%)\n",
            "  adding: content/logsRN-44L-50E/1572364491.2424731/plugins/ (stored 0%)\n",
            "  adding: content/logsRN-44L-50E/1572364491.2424731/plugins/profile/ (stored 0%)\n",
            "  adding: content/logsRN-44L-50E/1572364491.2424731/plugins/profile/2019-10-29_15-55-56/ (stored 0%)\n",
            "  adding: content/logsRN-44L-50E/1572364491.2424731/plugins/profile/2019-10-29_15-55-56/local.trace (deflated 96%)\n",
            "  adding: content/logsRN-44L-50E/1572364491.2424731/events.out.tfevents.1572364495.e52d0a16bf3c (deflated 92%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaqTtxb7S9lY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}