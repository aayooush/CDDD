{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Di-zfmjqFis",
        "colab_type": "code",
        "outputId": "d9dbc8b7-3c5c-4025-d441-8210c1fa9d6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive                \n",
        "drive.mount('/content/drive')   "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vAiTJYspSRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, Activation, BatchNormalization, Add, Input, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import Callback, LearningRateScheduler, TensorBoard\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "import time\n",
        "import pickle\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ksJ4ijlpUQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TimeHistory(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.times = []\n",
        "\n",
        "    def on_epoch_begin(self, batch, logs={}):\n",
        "        self.epoch_start_time = time.time()\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        self.times.append(time.time() - self.epoch_start_time)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_lb5Ug_pUa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet:\n",
        "    def __init__(self, n, framework, channels_first=False, initial_lr=0.01, nb_epochs=100):\n",
        "        self.n = n\n",
        "        self.framework = framework\n",
        "        self.initial_lr = initial_lr\n",
        "        self.nb_epochs = nb_epochs\n",
        "        self.weight_decay = 0.0005\n",
        "        self.channels_first = channels_first\n",
        "        self.data_format = \"channels_first\" if channels_first else \"channels_last\"\n",
        "        self.bn_axis = 1 if channels_first else -1\n",
        "        # Make model\n",
        "        self.model = self.make_model()\n",
        "        plot_model(self.model, to_file='ResNet.png')\n",
        "#         SVG(model_to_dot(self.model).create(prog='dot', format='svg'))\n",
        "\n",
        "    def subsumpling(self, output_channels, input_tensor):\n",
        "        return Conv2D(output_channels, kernel_size=1, strides=(2,2), data_format=self.data_format, kernel_regularizer=l2(self.weight_decay))(input_tensor)\n",
        "\n",
        "    def block(self, channles, input_tensor):\n",
        "\n",
        "        shortcut = input_tensor\n",
        "        x = BatchNormalization(axis=self.bn_axis)(input_tensor)\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = Conv2D(channles, kernel_size=3, padding=\"same\", data_format=self.data_format, kernel_regularizer=l2(self.weight_decay))(x)\n",
        "        x = BatchNormalization(axis=self.bn_axis)(x)\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = Conv2D(channles, kernel_size=3, padding=\"same\", data_format=self.data_format, kernel_regularizer=l2(self.weight_decay))(x)\n",
        "        return Add()([x, shortcut])\n",
        "\n",
        "    def make_model(self):\n",
        "        input = Input(shape=(3, 300, 300)) if self.channels_first else Input(shape=(300, 300, 3))\n",
        "        x = Conv2D(16, kernel_size=3, padding=\"same\", data_format=self.data_format, kernel_regularizer=l2(self.weight_decay))(input)\n",
        "        for i in range(self.n):\n",
        "            x = self.block(16, x)\n",
        "        # 16x16x32\n",
        "        x = self.subsumpling(32, x)\n",
        "        for i in range(self.n):\n",
        "            x = self.block(32, x)\n",
        "        # 8x8x64\n",
        "        x = self.subsumpling(64, x)\n",
        "        for i in range(self.n):\n",
        "            x = self.block(64, x)\n",
        "        # Global Average Pooling\n",
        "        x = GlobalAveragePooling2D(data_format=self.data_format)(x)\n",
        "        x = Dense(4, activation=\"softmax\")(x)\n",
        "        # model\n",
        "        model = Model(input, x)\n",
        "        return model\n",
        "\n",
        "    def lr_schduler(self, epoch):\n",
        "        x = self.initial_lr\n",
        "        if epoch >= self.nb_epochs * 0.5: x /= 10.0\n",
        "        if epoch >= self.nb_epochs * 0.75: x /= 10.0\n",
        "        return x\n",
        "\n",
        "    def train(self, TRAIN_PATH, VALIDATION_PATH):\n",
        "        self.model.summary()\n",
        "        self.model.compile(optimizer=SGD(lr=self.initial_lr, momentum=0.9), loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
        "        traingen = ImageDataGenerator(\n",
        "            rescale=1./255,\n",
        "            width_shift_range=4./32,\n",
        "            height_shift_range=4./32,\n",
        "            horizontal_flip=True)\n",
        "        valgen = ImageDataGenerator(\n",
        "            rescale=1./255)\n",
        "        # Callback\n",
        "        time_cb = TimeHistory()\n",
        "        lr_cb = LearningRateScheduler(self.lr_schduler)\n",
        "        tensorboard = TensorBoard(log_dir=\"./logsRN-2/{}\".format(time.time()), \n",
        "                          histogram_freq=0, \n",
        "                          write_graph=True, \n",
        "                          write_grads=False, \n",
        "                          write_images=False, \n",
        "                          embeddings_freq=0, \n",
        "                          embeddings_layer_names=None, \n",
        "                          embeddings_metadata=None, \n",
        "                          embeddings_data=None, \n",
        "                          update_freq='epoch')\n",
        "\n",
        "        # Train\n",
        "        history = self.model.fit_generator(traingen.flow_from_directory(TRAIN_PATH, \n",
        "                                                                        target_size=(300,300),\n",
        "                                                                        class_mode='categorical'), \n",
        "                                           epochs=100,\n",
        "                                           callbacks=[time_cb, lr_cb, tensorboard],\n",
        "                                           validation_data = valgen.flow_from_directory( VALIDATION_PATH,\n",
        "                                                                                          target_size=(300,300),\n",
        "                                                                                          class_mode='categorical')).history\n",
        "        history[\"time\"] = time_cb.times\n",
        "        \n",
        "        \n",
        "        self.model.save(\"cotton_disease-resnet.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DAOA1oJo_hj",
        "colab_type": "code",
        "outputId": "358a0914-8ea3-4825-b4f0-f813ad9e630a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# Main function\n",
        "def main(n, framework):\n",
        "    # layers = 6n+2\n",
        "    net = ResNet(n, framework, nb_epochs=1)\n",
        "    base_dir = '/content/drive/My Drive/B.E PROJECT/CNN CROP/data/disease/input'\n",
        "\n",
        "    TRAIN_PATH = os.path.join(base_dir, 'Training')\n",
        "    VALIDATION_PATH = os.path.join(base_dir, 'Validation')\n",
        "    net.train(TRAIN_PATH, VALIDATION_PATH)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main(4, \"keras_tf\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 300, 300, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 300, 300, 16) 448         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 300, 300, 16) 64          conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 300, 300, 16) 0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 300, 300, 16) 2320        activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 300, 300, 16) 64          conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 300, 300, 16) 0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 300, 300, 16) 2320        activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 300, 300, 16) 0           conv2d_44[0][0]                  \n",
            "                                                                 conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 300, 300, 16) 64          add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 300, 300, 16) 0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 300, 300, 16) 2320        activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 300, 300, 16) 64          conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 300, 300, 16) 0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 300, 300, 16) 2320        activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 300, 300, 16) 0           conv2d_46[0][0]                  \n",
            "                                                                 add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 300, 300, 16) 64          add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 300, 300, 16) 0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 300, 300, 16) 2320        activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 300, 300, 16) 64          conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 300, 300, 16) 0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 300, 300, 16) 2320        activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 300, 300, 16) 0           conv2d_48[0][0]                  \n",
            "                                                                 add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 300, 300, 16) 64          add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 300, 300, 16) 0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 300, 300, 16) 2320        activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 300, 300, 16) 64          conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 300, 300, 16) 0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 300, 300, 16) 2320        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 300, 300, 16) 0           conv2d_50[0][0]                  \n",
            "                                                                 add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 150, 150, 32) 544         add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 150, 150, 32) 128         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 150, 150, 32) 0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 150, 150, 32) 9248        activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 150, 150, 32) 128         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 150, 150, 32) 0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 150, 150, 32) 9248        activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 150, 150, 32) 0           conv2d_53[0][0]                  \n",
            "                                                                 conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 150, 150, 32) 128         add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 150, 150, 32) 0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 150, 150, 32) 9248        activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 150, 150, 32) 128         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 150, 150, 32) 0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 150, 150, 32) 9248        activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 150, 150, 32) 0           conv2d_55[0][0]                  \n",
            "                                                                 add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 150, 150, 32) 128         add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 150, 150, 32) 0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 150, 150, 32) 9248        activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 150, 150, 32) 128         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 150, 150, 32) 0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 150, 150, 32) 9248        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 150, 150, 32) 0           conv2d_57[0][0]                  \n",
            "                                                                 add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 150, 150, 32) 128         add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 150, 150, 32) 0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 150, 150, 32) 9248        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 150, 150, 32) 128         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 150, 150, 32) 0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 150, 150, 32) 9248        activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 150, 150, 32) 0           conv2d_59[0][0]                  \n",
            "                                                                 add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 75, 75, 64)   2112        add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 75, 75, 64)   256         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 75, 75, 64)   0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 75, 75, 64)   36928       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 75, 75, 64)   256         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 75, 75, 64)   0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 75, 75, 64)   36928       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 75, 75, 64)   0           conv2d_62[0][0]                  \n",
            "                                                                 conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 75, 75, 64)   256         add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 75, 75, 64)   0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 75, 75, 64)   36928       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 75, 75, 64)   256         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 75, 75, 64)   0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 75, 75, 64)   36928       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 75, 75, 64)   0           conv2d_64[0][0]                  \n",
            "                                                                 add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 75, 75, 64)   256         add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 75, 75, 64)   0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 75, 75, 64)   36928       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 75, 75, 64)   256         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 75, 75, 64)   0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 75, 75, 64)   36928       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 75, 75, 64)   0           conv2d_66[0][0]                  \n",
            "                                                                 add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 75, 75, 64)   256         add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 75, 75, 64)   0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 75, 75, 64)   36928       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 75, 75, 64)   256         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 75, 75, 64)   0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 75, 75, 64)   36928       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 75, 75, 64)   0           conv2d_68[0][0]                  \n",
            "                                                                 add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 64)           0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 4)            260         global_average_pooling2d_2[0][0] \n",
            "==================================================================================================\n",
            "Total params: 394,916\n",
            "Trainable params: 393,124\n",
            "Non-trainable params: 1,792\n",
            "__________________________________________________________________________________________________\n",
            "Found 432 images belonging to 4 classes.\n",
            "Found 160 images belonging to 4 classes.\n",
            "Epoch 1/100\n",
            "13/14 [==========================>...] - ETA: 2s - loss: 1.7071 - acc: 0.5400Epoch 1/100\n",
            "14/14 [==============================] - 46s 3s/step - loss: 1.6997 - acc: 0.5417 - val_loss: 16.0258 - val_acc: 0.2500\n",
            "Epoch 2/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 5.9586 - acc: 0.4075Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 6.1777 - acc: 0.4074 - val_loss: 19.8434 - val_acc: 0.2500\n",
            "Epoch 3/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 6.9586 - acc: 0.3925Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 6.8970 - acc: 0.3981 - val_loss: 7.2749 - val_acc: 0.3313\n",
            "Epoch 4/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 4.0626 - acc: 0.4575Epoch 1/100\n",
            "14/14 [==============================] - 40s 3s/step - loss: 4.0180 - acc: 0.4583 - val_loss: 3.3951 - val_acc: 0.4000\n",
            "Epoch 5/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 2.7624 - acc: 0.5725Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 2.6457 - acc: 0.5810 - val_loss: 3.1532 - val_acc: 0.3250\n",
            "Epoch 6/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 2.0142 - acc: 0.6725Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 1.9681 - acc: 0.6736 - val_loss: 2.8873 - val_acc: 0.3250\n",
            "Epoch 7/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.6871 - acc: 0.6975Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 1.6923 - acc: 0.6944 - val_loss: 2.7166 - val_acc: 0.3313\n",
            "Epoch 8/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.4542 - acc: 0.7375Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 1.4769 - acc: 0.7361 - val_loss: 2.4595 - val_acc: 0.3500\n",
            "Epoch 9/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.2993 - acc: 0.7450Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 1.3358 - acc: 0.7454 - val_loss: 2.2721 - val_acc: 0.3938\n",
            "Epoch 10/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.4267 - acc: 0.7725Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 1.3854 - acc: 0.7778 - val_loss: 2.1238 - val_acc: 0.4125\n",
            "Epoch 11/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.2882 - acc: 0.7975Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 1.2995 - acc: 0.7986 - val_loss: 2.0077 - val_acc: 0.4125\n",
            "Epoch 12/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.3171 - acc: 0.7900Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 1.3146 - acc: 0.7847 - val_loss: 1.8836 - val_acc: 0.4563\n",
            "Epoch 13/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.1142 - acc: 0.8175Epoch 1/100\n",
            "14/14 [==============================] - 40s 3s/step - loss: 1.1410 - acc: 0.8102 - val_loss: 1.8038 - val_acc: 0.4750\n",
            "Epoch 14/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.0900 - acc: 0.8125Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 1.0986 - acc: 0.8125 - val_loss: 1.7650 - val_acc: 0.5063\n",
            "Epoch 15/100\n",
            "13/14 [==========================>...] - ETA: 2s - loss: 1.0899 - acc: 0.8149Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 1.0747 - acc: 0.8148 - val_loss: 1.7121 - val_acc: 0.5188\n",
            "Epoch 16/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.0344 - acc: 0.8425Epoch 1/100\n",
            "14/14 [==============================] - 40s 3s/step - loss: 1.0544 - acc: 0.8403 - val_loss: 1.6077 - val_acc: 0.5500\n",
            "Epoch 17/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.0687 - acc: 0.8150Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 1.0602 - acc: 0.8194 - val_loss: 1.5442 - val_acc: 0.5562\n",
            "Epoch 18/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.0134 - acc: 0.8175Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 1.0045 - acc: 0.8218 - val_loss: 1.5402 - val_acc: 0.5625\n",
            "Epoch 19/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.9651 - acc: 0.8475Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.9568 - acc: 0.8495 - val_loss: 1.5009 - val_acc: 0.5750\n",
            "Epoch 20/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.9850 - acc: 0.8475Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 1.0060 - acc: 0.8449 - val_loss: 1.4664 - val_acc: 0.5875\n",
            "Epoch 21/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.9865 - acc: 0.8400Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.9822 - acc: 0.8403 - val_loss: 1.4483 - val_acc: 0.6000\n",
            "Epoch 22/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.9782 - acc: 0.8400Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.9872 - acc: 0.8426 - val_loss: 1.4244 - val_acc: 0.6375\n",
            "Epoch 23/100\n",
            "13/14 [==========================>...] - ETA: 2s - loss: 0.9691 - acc: 0.8389Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.9561 - acc: 0.8426 - val_loss: 1.3709 - val_acc: 0.6187\n",
            "Epoch 24/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 1.0373 - acc: 0.8225Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 1.0212 - acc: 0.8218 - val_loss: 1.3772 - val_acc: 0.6750\n",
            "Epoch 25/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.9719 - acc: 0.8450Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.9796 - acc: 0.8403 - val_loss: 1.3491 - val_acc: 0.6812\n",
            "Epoch 26/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8945 - acc: 0.8575Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8834 - acc: 0.8611 - val_loss: 1.3474 - val_acc: 0.6812\n",
            "Epoch 27/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.9229 - acc: 0.8350Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.9267 - acc: 0.8356 - val_loss: 1.4167 - val_acc: 0.6687\n",
            "Epoch 28/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.9225 - acc: 0.8425Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.9387 - acc: 0.8380 - val_loss: 1.3895 - val_acc: 0.6687\n",
            "Epoch 29/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.9469 - acc: 0.8325Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.9380 - acc: 0.8380 - val_loss: 1.2872 - val_acc: 0.6875\n",
            "Epoch 30/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.9171 - acc: 0.8475Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.9171 - acc: 0.8449 - val_loss: 1.2816 - val_acc: 0.7063\n",
            "Epoch 31/100\n",
            "13/14 [==========================>...] - ETA: 2s - loss: 0.9377 - acc: 0.8438Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.9214 - acc: 0.8449 - val_loss: 1.2549 - val_acc: 0.7563\n",
            "Epoch 32/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8929 - acc: 0.8625Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8801 - acc: 0.8681 - val_loss: 1.2366 - val_acc: 0.7688\n",
            "Epoch 33/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8946 - acc: 0.8575Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.9218 - acc: 0.8519 - val_loss: 1.1554 - val_acc: 0.7563\n",
            "Epoch 34/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8698 - acc: 0.8775Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8852 - acc: 0.8657 - val_loss: 1.2281 - val_acc: 0.7937\n",
            "Epoch 35/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.9041 - acc: 0.8500Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.9076 - acc: 0.8449 - val_loss: 1.1413 - val_acc: 0.7750\n",
            "Epoch 36/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8774 - acc: 0.8475Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8833 - acc: 0.8426 - val_loss: 1.1224 - val_acc: 0.7937\n",
            "Epoch 37/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.9521 - acc: 0.8625Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.9519 - acc: 0.8542 - val_loss: 1.1600 - val_acc: 0.7937\n",
            "Epoch 38/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8605 - acc: 0.8525Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8651 - acc: 0.8472 - val_loss: 1.1539 - val_acc: 0.7937\n",
            "Epoch 39/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8697 - acc: 0.8650Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8610 - acc: 0.8681 - val_loss: 1.0951 - val_acc: 0.7937\n",
            "Epoch 40/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.9118 - acc: 0.8475Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.9171 - acc: 0.8472 - val_loss: 1.0462 - val_acc: 0.8000\n",
            "Epoch 41/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8637 - acc: 0.8700Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8589 - acc: 0.8704 - val_loss: 1.0671 - val_acc: 0.8062\n",
            "Epoch 42/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8595 - acc: 0.8725Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8701 - acc: 0.8704 - val_loss: 1.0360 - val_acc: 0.8000\n",
            "Epoch 43/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8462 - acc: 0.8800Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8579 - acc: 0.8796 - val_loss: 1.0211 - val_acc: 0.8125\n",
            "Epoch 44/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8297 - acc: 0.8750Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8355 - acc: 0.8634 - val_loss: 1.0152 - val_acc: 0.8188\n",
            "Epoch 45/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8568 - acc: 0.8850Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8553 - acc: 0.8843 - val_loss: 1.0349 - val_acc: 0.8000\n",
            "Epoch 46/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8314 - acc: 0.8800Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8409 - acc: 0.8750 - val_loss: 1.0286 - val_acc: 0.7937\n",
            "Epoch 47/100\n",
            "13/14 [==========================>...] - ETA: 2s - loss: 0.8720 - acc: 0.8582Epoch 1/100\n",
            "14/14 [==============================] - 40s 3s/step - loss: 0.8678 - acc: 0.8588 - val_loss: 1.0276 - val_acc: 0.8062\n",
            "Epoch 48/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8596 - acc: 0.8600Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8473 - acc: 0.8681 - val_loss: 1.0557 - val_acc: 0.8188\n",
            "Epoch 49/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8240 - acc: 0.8850Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8227 - acc: 0.8866 - val_loss: 1.0295 - val_acc: 0.8250\n",
            "Epoch 50/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8153 - acc: 0.8775Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8295 - acc: 0.8773 - val_loss: 1.0261 - val_acc: 0.8188\n",
            "Epoch 51/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8283 - acc: 0.8725Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8192 - acc: 0.8750 - val_loss: 1.0208 - val_acc: 0.8062\n",
            "Epoch 52/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8199 - acc: 0.8725Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8264 - acc: 0.8704 - val_loss: 1.0186 - val_acc: 0.8250\n",
            "Epoch 53/100\n",
            "13/14 [==========================>...] - ETA: 2s - loss: 0.8651 - acc: 0.8654Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8574 - acc: 0.8634 - val_loss: 0.9991 - val_acc: 0.8375\n",
            "Epoch 54/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8235 - acc: 0.8775Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8227 - acc: 0.8750 - val_loss: 0.9881 - val_acc: 0.8313\n",
            "Epoch 55/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8386 - acc: 0.8625Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8565 - acc: 0.8565 - val_loss: 0.9793 - val_acc: 0.8188\n",
            "Epoch 56/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8423 - acc: 0.8600Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8478 - acc: 0.8565 - val_loss: 0.9827 - val_acc: 0.8188\n",
            "Epoch 57/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8419 - acc: 0.8600Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8381 - acc: 0.8657 - val_loss: 1.0079 - val_acc: 0.8125\n",
            "Epoch 58/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8192 - acc: 0.8700Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8219 - acc: 0.8681 - val_loss: 0.9792 - val_acc: 0.8250\n",
            "Epoch 59/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8238 - acc: 0.8800Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8242 - acc: 0.8750 - val_loss: 1.0510 - val_acc: 0.8313\n",
            "Epoch 60/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.7969 - acc: 0.8775Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.7952 - acc: 0.8773 - val_loss: 0.9948 - val_acc: 0.8438\n",
            "Epoch 61/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8421 - acc: 0.8750Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8300 - acc: 0.8796 - val_loss: 0.9621 - val_acc: 0.8438\n",
            "Epoch 62/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8110 - acc: 0.8775Epoch 1/100\n",
            "14/14 [==============================] - 40s 3s/step - loss: 0.8104 - acc: 0.8773 - val_loss: 1.0238 - val_acc: 0.8250\n",
            "Epoch 63/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.7820 - acc: 0.8900Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.7901 - acc: 0.8889 - val_loss: 0.9566 - val_acc: 0.8375\n",
            "Epoch 64/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8181 - acc: 0.8750Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.7995 - acc: 0.8843 - val_loss: 0.9611 - val_acc: 0.8125\n",
            "Epoch 65/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8021 - acc: 0.8750Epoch 1/100\n",
            "14/14 [==============================] - 40s 3s/step - loss: 0.8019 - acc: 0.8750 - val_loss: 0.9800 - val_acc: 0.8313\n",
            "Epoch 66/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8125 - acc: 0.8950Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8210 - acc: 0.8935 - val_loss: 0.9932 - val_acc: 0.8250\n",
            "Epoch 67/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8164 - acc: 0.8875Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8082 - acc: 0.8935 - val_loss: 0.9591 - val_acc: 0.8250\n",
            "Epoch 68/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.7946 - acc: 0.8975Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8022 - acc: 0.8958 - val_loss: 0.9367 - val_acc: 0.8250\n",
            "Epoch 69/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.7822 - acc: 0.8975Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.7835 - acc: 0.8935 - val_loss: 0.9215 - val_acc: 0.8375\n",
            "Epoch 70/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.7725 - acc: 0.8950Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.7692 - acc: 0.8981 - val_loss: 0.9307 - val_acc: 0.8188\n",
            "Epoch 71/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.7948 - acc: 0.8825Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.7911 - acc: 0.8819 - val_loss: 0.9131 - val_acc: 0.8500\n",
            "Epoch 72/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.7772 - acc: 0.9050Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.7863 - acc: 0.9005 - val_loss: 0.9189 - val_acc: 0.8375\n",
            "Epoch 73/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8191 - acc: 0.8850Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8298 - acc: 0.8819 - val_loss: 0.9452 - val_acc: 0.8438\n",
            "Epoch 74/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.7909 - acc: 0.9075Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8043 - acc: 0.9051 - val_loss: 0.9879 - val_acc: 0.8313\n",
            "Epoch 75/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.7827 - acc: 0.8800Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.7909 - acc: 0.8796 - val_loss: 0.9406 - val_acc: 0.8438\n",
            "Epoch 76/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.7916 - acc: 0.8900Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8001 - acc: 0.8889 - val_loss: 0.9191 - val_acc: 0.8562\n",
            "Epoch 77/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8110 - acc: 0.8875Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8040 - acc: 0.8889 - val_loss: 0.9312 - val_acc: 0.8625\n",
            "Epoch 78/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8101 - acc: 0.8875Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8031 - acc: 0.8912 - val_loss: 0.9261 - val_acc: 0.8562\n",
            "Epoch 79/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8009 - acc: 0.8925Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.7880 - acc: 0.8981 - val_loss: 0.9256 - val_acc: 0.8438\n",
            "Epoch 80/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8372 - acc: 0.8725Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8308 - acc: 0.8750 - val_loss: 0.8859 - val_acc: 0.8562\n",
            "Epoch 81/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.7718 - acc: 0.9000Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.7761 - acc: 0.8912 - val_loss: 0.8806 - val_acc: 0.8438\n",
            "Epoch 82/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8806 - acc: 0.9000Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8760 - acc: 0.8958 - val_loss: 1.0259 - val_acc: 0.8313\n",
            "Epoch 83/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.7628 - acc: 0.8950Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.7681 - acc: 0.8958 - val_loss: 0.8853 - val_acc: 0.8500\n",
            "Epoch 84/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.7876 - acc: 0.8900Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.7936 - acc: 0.8866 - val_loss: 0.8776 - val_acc: 0.8813\n",
            "Epoch 85/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.7934 - acc: 0.8900Epoch 1/100\n",
            "14/14 [==============================] - 40s 3s/step - loss: 0.7831 - acc: 0.8958 - val_loss: 0.8751 - val_acc: 0.8750\n",
            "Epoch 86/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8001 - acc: 0.8750Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8036 - acc: 0.8750 - val_loss: 0.8690 - val_acc: 0.8500\n",
            "Epoch 87/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.7833 - acc: 0.9000Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.7867 - acc: 0.9028 - val_loss: 0.8810 - val_acc: 0.8438\n",
            "Epoch 88/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.7767 - acc: 0.9025Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8002 - acc: 0.8981 - val_loss: 0.8852 - val_acc: 0.8375\n",
            "Epoch 89/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8170 - acc: 0.8800Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8156 - acc: 0.8819 - val_loss: 0.8679 - val_acc: 0.8625\n",
            "Epoch 90/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.7888 - acc: 0.8875Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.7765 - acc: 0.8958 - val_loss: 0.9154 - val_acc: 0.8375\n",
            "Epoch 91/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.7438 - acc: 0.9125Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.7504 - acc: 0.9097 - val_loss: 0.8908 - val_acc: 0.8375\n",
            "Epoch 92/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.7941 - acc: 0.8825Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.7907 - acc: 0.8819 - val_loss: 0.8894 - val_acc: 0.8500\n",
            "Epoch 93/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.8134 - acc: 0.8900Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.8104 - acc: 0.8889 - val_loss: 0.8736 - val_acc: 0.8562\n",
            "Epoch 94/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.7912 - acc: 0.8800Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.7851 - acc: 0.8773 - val_loss: 0.8917 - val_acc: 0.8562\n",
            "Epoch 95/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.7980 - acc: 0.8825Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.7937 - acc: 0.8819 - val_loss: 0.8611 - val_acc: 0.8625\n",
            "Epoch 96/100\n",
            "13/14 [==========================>...] - ETA: 2s - loss: 0.7421 - acc: 0.9014Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.7447 - acc: 0.9005 - val_loss: 0.8635 - val_acc: 0.8562\n",
            "Epoch 97/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.7562 - acc: 0.8950Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.7532 - acc: 0.8958 - val_loss: 0.8714 - val_acc: 0.8438\n",
            "Epoch 98/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.7480 - acc: 0.9050Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.7486 - acc: 0.9051 - val_loss: 0.8658 - val_acc: 0.8562\n",
            "Epoch 99/100\n",
            "13/14 [==========================>...] - ETA: 1s - loss: 0.7461 - acc: 0.9175Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.7462 - acc: 0.9167 - val_loss: 0.8581 - val_acc: 0.8625\n",
            "Epoch 100/100\n",
            "13/14 [==========================>...] - ETA: 2s - loss: 0.7486 - acc: 0.8990Epoch 1/100\n",
            "14/14 [==============================] - 41s 3s/step - loss: 0.7399 - acc: 0.9028 - val_loss: 0.8518 - val_acc: 0.8562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsyPc3-ir8YW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cnyYNFOS3rF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "843d63fe-f64e-46d8-963e-6b220f235cd9"
      },
      "source": [
        "!zip -r /content/resnet26.zip /content/logsRN-2\n",
        "from google.colab import files\n",
        "files.download(\"/content/resnet26.zip\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/logsRN-2/ (stored 0%)\n",
            "  adding: content/logsRN-2/1572249998.257617/ (stored 0%)\n",
            "  adding: content/logsRN-2/1572249998.257617/events.out.tfevents.1572250011.349f101d8725.profile-empty (deflated 5%)\n",
            "  adding: content/logsRN-2/1572249998.257617/events.out.tfevents.1572249998.349f101d8725 (deflated 92%)\n",
            "  adding: content/logsRN-2/1572249998.257617/plugins/ (stored 0%)\n",
            "  adding: content/logsRN-2/1572249998.257617/plugins/profile/ (stored 0%)\n",
            "  adding: content/logsRN-2/1572249998.257617/plugins/profile/2019-10-28_08-06-51/ (stored 0%)\n",
            "  adding: content/logsRN-2/1572249998.257617/plugins/profile/2019-10-28_08-06-51/local.trace (deflated 96%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaqTtxb7S9lY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}