{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "7Di-zfmjqFis",
    "outputId": "e9a8fcbf-d742-4d94-8142-742b3e87f5c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive                \n",
    "# drive.mount('/content/drive')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "id": "2vAiTJYspSRF",
    "outputId": "400f1608-8d5a-4086-9b4f-6a26c2e869ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aayushsingh/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/aayushsingh/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/aayushsingh/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/aayushsingh/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/aayushsingh/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/aayushsingh/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/aayushsingh/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/aayushsingh/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/aayushsingh/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/aayushsingh/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/aayushsingh/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/aayushsingh/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Activation, BatchNormalization, Add, Input, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import Callback, LearningRateScheduler, TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import SVG\n",
    "import time\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ksJ4ijlpUQi"
   },
   "outputs": [],
   "source": [
    "class TimeHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_start_time = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j_lb5Ug_pUa4"
   },
   "outputs": [],
   "source": [
    "class ResNet:\n",
    "    def __init__(self, n, framework, channels_first=False, initial_lr=0.01, nb_epochs=100):\n",
    "        self.n = n\n",
    "        self.framework = framework\n",
    "        self.initial_lr = initial_lr\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.weight_decay = 0.0005\n",
    "        self.channels_first = channels_first\n",
    "        self.data_format = \"channels_first\" if channels_first else \"channels_last\"\n",
    "        self.bn_axis = 1 if channels_first else -1\n",
    "        # Make model\n",
    "        self.model = self.make_model()\n",
    "        plot_model(self.model, to_file='ResNet.png')\n",
    "#         SVG(model_to_dot(self.model).create(prog='dot', format='svg'))\n",
    "\n",
    "    def subsumpling(self, output_channels, input_tensor):\n",
    "        return Conv2D(output_channels, kernel_size=1, strides=(2,2), data_format=self.data_format, kernel_regularizer=l2(self.weight_decay))(input_tensor)\n",
    "\n",
    "    def block(self, channles, input_tensor):\n",
    "\n",
    "        shortcut = input_tensor\n",
    "        x = BatchNormalization(axis=self.bn_axis)(input_tensor)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2D(channles, kernel_size=3, padding=\"same\", data_format=self.data_format, kernel_regularizer=l2(self.weight_decay))(x)\n",
    "        x = BatchNormalization(axis=self.bn_axis)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2D(channles, kernel_size=3, padding=\"same\", data_format=self.data_format, kernel_regularizer=l2(self.weight_decay))(x)\n",
    "        return Add()([x, shortcut])\n",
    "\n",
    "    def make_model(self):\n",
    "        input = Input(shape=(3, 200, 200)) if self.channels_first else Input(shape=(200, 200, 3))\n",
    "        x = Conv2D(16, kernel_size=3, padding=\"same\", data_format=self.data_format, kernel_regularizer=l2(self.weight_decay))(input)\n",
    "        for i in range(self.n):\n",
    "            x = self.block(16, x)\n",
    "        # 16x16x32\n",
    "        x = self.subsumpling(32, x)\n",
    "        for i in range(self.n):\n",
    "            x = self.block(32, x)\n",
    "        # 8x8x64\n",
    "        x = self.subsumpling(64, x)\n",
    "        for i in range(self.n):\n",
    "            x = self.block(64, x)\n",
    "        # Global Average Pooling\n",
    "        x = GlobalAveragePooling2D(data_format=self.data_format)(x)\n",
    "        x = Dense(4, activation=\"softmax\")(x)\n",
    "        # model\n",
    "        model = Model(input, x)\n",
    "        return model\n",
    "\n",
    "    def lr_schduler(self, epoch):\n",
    "        x = self.initial_lr\n",
    "        if epoch >= self.nb_epochs * 0.5: x /= 5.0\n",
    "        if epoch >= self.nb_epochs * 0.75: x /= 5.0\n",
    "        return x\n",
    "\n",
    "    def train(self, TRAIN_PATH, VALIDATION_PATH):\n",
    "        self.model.summary()\n",
    "        self.model.compile(optimizer=SGD(lr=self.initial_lr, momentum=0.9), loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "        traingen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            width_shift_range=4./32,\n",
    "            height_shift_range=4./32,\n",
    "            horizontal_flip=True)\n",
    "        valgen = ImageDataGenerator(\n",
    "            rescale=1./255)\n",
    "        # Callback\n",
    "        time_cb = TimeHistory()\n",
    "        lr_cb = LearningRateScheduler(self.lr_schduler)\n",
    "        tensorboard = TensorBoard(log_dir=\"./logsRN-20L-100E/{}\".format(time.time()), \n",
    "                          histogram_freq=0, \n",
    "                          write_graph=True, \n",
    "                          write_grads=False, \n",
    "                          write_images=False, \n",
    "                          embeddings_freq=0, \n",
    "                          embeddings_layer_names=None, \n",
    "                          embeddings_metadata=None, \n",
    "                          embeddings_data=None, \n",
    "                          update_freq='epoch')\n",
    "        filepath = \"checkpoints/models-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "        # Train\n",
    "        history = self.model.fit_generator(traingen.flow_from_directory(TRAIN_PATH, \n",
    "                                                                        target_size=(200,200),\n",
    "                                                                        class_mode='categorical'), \n",
    "                                           epochs=100,\n",
    "                                           callbacks=[time_cb, lr_cb, tensorboard, checkpoint],\n",
    "                                           validation_data = valgen.flow_from_directory( VALIDATION_PATH,\n",
    "                                                                                          target_size=(200,200),\n",
    "                                                                                          class_mode='categorical')).history\n",
    "        history[\"time\"] = time_cb.times\n",
    "        \n",
    "        \n",
    "        self.model.save(\"cotton_disease-resnet50E44L-2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4DAOA1oJo_hj",
    "outputId": "6d3cedf9-bfc7-4f95-f990-66d002d1eb4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/aayushsingh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 200, 200, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 200, 200, 16) 448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 200, 200, 16) 64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 200, 200, 16) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 200, 200, 16) 2320        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 200, 200, 16) 64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 200, 200, 16) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 200, 200, 16) 2320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 200, 200, 16) 0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 200, 200, 16) 64          add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 200, 200, 16) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 200, 200, 16) 2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 200, 200, 16) 64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 200, 200, 16) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 200, 200, 16) 2320        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 200, 200, 16) 0           conv2d_4[0][0]                   \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 200, 200, 16) 64          add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 200, 200, 16) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 200, 200, 16) 2320        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 200, 200, 16) 64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 200, 200, 16) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 200, 200, 16) 2320        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 200, 200, 16) 0           conv2d_6[0][0]                   \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 100, 100, 32) 544         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 100, 100, 32) 128         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 100, 100, 32) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 100, 100, 32) 9248        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 100, 100, 32) 128         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 100, 100, 32) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 100, 100, 32) 9248        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 100, 100, 32) 0           conv2d_9[0][0]                   \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 100, 100, 32) 128         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 100, 100, 32) 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 100, 100, 32) 9248        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 100, 100, 32) 128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 100, 100, 32) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 100, 100, 32) 9248        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 100, 100, 32) 0           conv2d_11[0][0]                  \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 100, 100, 32) 128         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 100, 100, 32) 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 100, 100, 32) 9248        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 100, 100, 32) 128         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 100, 100, 32) 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 100, 100, 32) 9248        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 100, 100, 32) 0           conv2d_13[0][0]                  \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 50, 50, 64)   2112        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 50, 50, 64)   256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 50, 50, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 50, 50, 64)   36928       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 50, 50, 64)   256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 50, 50, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 50, 50, 64)   36928       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 50, 50, 64)   0           conv2d_16[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 50, 50, 64)   256         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 50, 50, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 50, 50, 64)   36928       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 50, 50, 64)   256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 50, 50, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 50, 50, 64)   36928       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 50, 50, 64)   0           conv2d_18[0][0]                  \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 50, 50, 64)   256         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 50, 50, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 50, 50, 64)   36928       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 50, 50, 64)   256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 50, 50, 64)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 50, 50, 64)   36928       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 50, 50, 64)   0           conv2d_20[0][0]                  \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 64)           0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 4)            260         global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 297,028\n",
      "Trainable params: 295,684\n",
      "Non-trainable params: 1,344\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 432 images belonging to 4 classes.\n",
      "Found 160 images belonging to 4 classes.\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Main function\n",
    "def main(n, framework):\n",
    "    # layers = 6n+2\n",
    "    net = ResNet(n, framework, nb_epochs=1)\n",
    "    base_dir = '../../CNN_Data'\n",
    "\n",
    "    TRAIN_PATH = os.path.join(base_dir, 'Training')\n",
    "    VALIDATION_PATH = os.path.join(base_dir, 'Validation')\n",
    "    net.train(TRAIN_PATH, VALIDATION_PATH)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(3, \"keras_tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "RsyPc3-ir8YW",
    "outputId": "36170639-1952-4b31-dbc0-5586e4bafc1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cotton_disease-resnet50E44L.h5  'logsRN-3(100E 44L)'   sample_data\n",
      " drive\t\t\t\t  ResNet.png\n"
     ]
    }
   ],
   "source": [
    "  !ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "8cnyYNFOS3rF",
    "outputId": "fa08cdfe-bcec-47f7-9a72-fad7e5fdb223"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: content/logsRN-20L-100E/ (stored 0%)\n",
      "updating: content/logsRN-20L-100E/1572362288.7122812/ (stored 0%)\n",
      "updating: content/logsRN-20L-100E/1572362288.7122812/events.out.tfevents.1572362294.663fdcb55619 (deflated 91%)\n",
      "updating: content/logsRN-20L-100E/1572362288.7122812/events.out.tfevents.1572362346.663fdcb55619.profile-empty (deflated 8%)\n",
      "updating: content/logsRN-20L-100E/1572362288.7122812/plugins/ (stored 0%)\n",
      "updating: content/logsRN-20L-100E/1572362288.7122812/plugins/profile/ (stored 0%)\n",
      "updating: content/logsRN-20L-100E/1572362288.7122812/plugins/profile/2019-10-29_15-19-06/ (stored 0%)\n",
      "updating: content/logsRN-20L-100E/1572362288.7122812/plugins/profile/2019-10-29_15-19-06/local.trace (deflated 96%)\n"
     ]
    }
   ],
   "source": [
    "# !zip -r \"/content/resnet20L100E.zip\" \"/content/logsRN-20L-100E/\"\n",
    "# from google.colab import files\n",
    "# files.download(\"/content/resnet20L100E.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OaqTtxb7S9lY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ResNet-20L-100E.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
