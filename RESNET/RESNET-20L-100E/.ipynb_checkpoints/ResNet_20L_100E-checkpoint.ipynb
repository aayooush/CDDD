{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "7Di-zfmjqFis",
    "outputId": "095ecdaa-ee7b-4753-cd89-c1bdc8422540"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive                \n",
    "drive.mount('/content/drive')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "id": "2vAiTJYspSRF",
    "outputId": "9b3de159-ac6b-490a-8619-6b8a05bf4723"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Activation, BatchNormalization, Add, Input, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import Callback, LearningRateScheduler, TensorBoard\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import SVG\n",
    "import time\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ksJ4ijlpUQi"
   },
   "outputs": [],
   "source": [
    "class TimeHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_start_time = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j_lb5Ug_pUa4"
   },
   "outputs": [],
   "source": [
    "class ResNet:\n",
    "    def __init__(self, n, framework, channels_first=False, initial_lr=0.01, nb_epochs=100):\n",
    "        self.n = n\n",
    "        self.framework = framework\n",
    "        self.initial_lr = initial_lr\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.weight_decay = 0.0005\n",
    "        self.channels_first = channels_first\n",
    "        self.data_format = \"channels_first\" if channels_first else \"channels_last\"\n",
    "        self.bn_axis = 1 if channels_first else -1\n",
    "        # Make model\n",
    "        self.model = self.make_model()\n",
    "        plot_model(self.model, to_file='ResNet.png')\n",
    "#         SVG(model_to_dot(self.model).create(prog='dot', format='svg'))\n",
    "\n",
    "    def subsumpling(self, output_channels, input_tensor):\n",
    "        return Conv2D(output_channels, kernel_size=1, strides=(2,2), data_format=self.data_format, kernel_regularizer=l2(self.weight_decay))(input_tensor)\n",
    "\n",
    "    def block(self, channles, input_tensor):\n",
    "\n",
    "        shortcut = input_tensor\n",
    "        x = BatchNormalization(axis=self.bn_axis)(input_tensor)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2D(channles, kernel_size=3, padding=\"same\", data_format=self.data_format, kernel_regularizer=l2(self.weight_decay))(x)\n",
    "        x = BatchNormalization(axis=self.bn_axis)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2D(channles, kernel_size=3, padding=\"same\", data_format=self.data_format, kernel_regularizer=l2(self.weight_decay))(x)\n",
    "        return Add()([x, shortcut])\n",
    "\n",
    "    def make_model(self):\n",
    "        input = Input(shape=(3, 200, 200)) if self.channels_first else Input(shape=(200, 200, 3))\n",
    "        x = Conv2D(16, kernel_size=3, padding=\"same\", data_format=self.data_format, kernel_regularizer=l2(self.weight_decay))(input)\n",
    "        for i in range(self.n):\n",
    "            x = self.block(16, x)\n",
    "        # 16x16x32\n",
    "        x = self.subsumpling(32, x)\n",
    "        for i in range(self.n):\n",
    "            x = self.block(32, x)\n",
    "        # 8x8x64\n",
    "        x = self.subsumpling(64, x)\n",
    "        for i in range(self.n):\n",
    "            x = self.block(64, x)\n",
    "        # Global Average Pooling\n",
    "        x = GlobalAveragePooling2D(data_format=self.data_format)(x)\n",
    "        x = Dense(4, activation=\"softmax\")(x)\n",
    "        # model\n",
    "        model = Model(input, x)\n",
    "        return model\n",
    "\n",
    "    def lr_schduler(self, epoch):\n",
    "        x = self.initial_lr\n",
    "        if epoch >= self.nb_epochs * 0.5: x /= 5.0\n",
    "        if epoch >= self.nb_epochs * 0.75: x /= 5.0\n",
    "        return x\n",
    "\n",
    "    def train(self, TRAIN_PATH, VALIDATION_PATH):\n",
    "        self.model.summary()\n",
    "        self.model.compile(optimizer=SGD(lr=self.initial_lr, momentum=0.9), loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "        traingen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            width_shift_range=4./32,\n",
    "            height_shift_range=4./32,\n",
    "            horizontal_flip=True)\n",
    "        valgen = ImageDataGenerator(\n",
    "            rescale=1./255)\n",
    "        # Callback\n",
    "        time_cb = TimeHistory()\n",
    "        lr_cb = LearningRateScheduler(self.lr_schduler)\n",
    "        tensorboard = TensorBoard(log_dir=\"./logsRN-20L-100E/{}\".format(time.time()), \n",
    "                          histogram_freq=0, \n",
    "                          write_graph=True, \n",
    "                          write_grads=False, \n",
    "                          write_images=False, \n",
    "                          embeddings_freq=0, \n",
    "                          embeddings_layer_names=None, \n",
    "                          embeddings_metadata=None, \n",
    "                          embeddings_data=None, \n",
    "                          update_freq='epoch')\n",
    "\n",
    "        # Train\n",
    "        history = self.model.fit_generator(traingen.flow_from_directory(TRAIN_PATH, \n",
    "                                                                        target_size=(200,200),\n",
    "                                                                        class_mode='categorical'), \n",
    "                                           epochs=100,\n",
    "                                           callbacks=[time_cb, lr_cb, tensorboard],\n",
    "                                           validation_data = valgen.flow_from_directory( VALIDATION_PATH,\n",
    "                                                                                          target_size=(200,200),\n",
    "                                                                                          class_mode='categorical')).history\n",
    "        history[\"time\"] = time_cb.times\n",
    "        \n",
    "        \n",
    "        self.model.save(\"cotton_disease-resnet50E44L.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4DAOA1oJo_hj",
    "outputId": "dc572b0e-edec-45d9-fcbe-214b8894c422"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 200, 200, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 200, 200, 16) 448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 200, 200, 16) 64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 200, 200, 16) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 200, 200, 16) 2320        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 200, 200, 16) 64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 200, 200, 16) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 200, 200, 16) 2320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 200, 200, 16) 0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 200, 200, 16) 64          add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 200, 200, 16) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 200, 200, 16) 2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 200, 200, 16) 64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 200, 200, 16) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 200, 200, 16) 2320        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 200, 200, 16) 0           conv2d_4[0][0]                   \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 200, 200, 16) 64          add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 200, 200, 16) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 200, 200, 16) 2320        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 200, 200, 16) 64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 200, 200, 16) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 200, 200, 16) 2320        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 200, 200, 16) 0           conv2d_6[0][0]                   \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 100, 100, 32) 544         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 100, 100, 32) 128         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 100, 100, 32) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 100, 100, 32) 9248        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 100, 100, 32) 128         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 100, 100, 32) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 100, 100, 32) 9248        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 100, 100, 32) 0           conv2d_9[0][0]                   \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 100, 100, 32) 128         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 100, 100, 32) 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 100, 100, 32) 9248        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 100, 100, 32) 128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 100, 100, 32) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 100, 100, 32) 9248        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 100, 100, 32) 0           conv2d_11[0][0]                  \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 100, 100, 32) 128         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 100, 100, 32) 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 100, 100, 32) 9248        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 100, 100, 32) 128         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 100, 100, 32) 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 100, 100, 32) 9248        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 100, 100, 32) 0           conv2d_13[0][0]                  \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 50, 50, 64)   2112        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 50, 50, 64)   256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 50, 50, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 50, 50, 64)   36928       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 50, 50, 64)   256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 50, 50, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 50, 50, 64)   36928       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 50, 50, 64)   0           conv2d_16[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 50, 50, 64)   256         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 50, 50, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 50, 50, 64)   36928       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 50, 50, 64)   256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 50, 50, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 50, 50, 64)   36928       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 50, 50, 64)   0           conv2d_18[0][0]                  \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 50, 50, 64)   256         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 50, 50, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 50, 50, 64)   36928       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 50, 50, 64)   256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 50, 50, 64)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 50, 50, 64)   36928       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 50, 50, 64)   0           conv2d_20[0][0]                  \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 64)           0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 4)            260         global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 297,028\n",
      "Trainable params: 295,684\n",
      "Non-trainable params: 1,344\n",
      "__________________________________________________________________________________________________\n",
      "Found 432 images belonging to 4 classes.\n",
      "Found 160 images belonging to 4 classes.\n",
      "Epoch 1/100\n",
      "13/14 [==========================>...] - ETA: 16s - loss: 1.7915 - acc: 0.4650Epoch 1/100\n",
      "14/14 [==============================] - 318s 23s/step - loss: 1.7737 - acc: 0.4722 - val_loss: 3.1245 - val_acc: 0.3438\n",
      "Epoch 2/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 3.1052 - acc: 0.4775Epoch 1/100\n",
      "14/14 [==============================] - 23s 2s/step - loss: 3.0506 - acc: 0.4884 - val_loss: 9.6604 - val_acc: 0.3375\n",
      "Epoch 3/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 3.2003 - acc: 0.5275Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 3.1193 - acc: 0.5394 - val_loss: 3.6074 - val_acc: 0.2500\n",
      "Epoch 4/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 2.1120 - acc: 0.5425Epoch 1/100\n",
      "14/14 [==============================] - 27s 2s/step - loss: 2.0784 - acc: 0.5417 - val_loss: 2.0743 - val_acc: 0.3250\n",
      "Epoch 5/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.3833 - acc: 0.6025Epoch 1/100\n",
      "14/14 [==============================] - 25s 2s/step - loss: 1.3796 - acc: 0.6019 - val_loss: 2.3073 - val_acc: 0.3500\n",
      "Epoch 6/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.1676 - acc: 0.7175Epoch 1/100\n",
      "14/14 [==============================] - 27s 2s/step - loss: 1.1577 - acc: 0.7176 - val_loss: 2.3688 - val_acc: 0.3250\n",
      "Epoch 7/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.0689 - acc: 0.7900Epoch 1/100\n",
      "14/14 [==============================] - 27s 2s/step - loss: 1.0665 - acc: 0.7894 - val_loss: 2.3423 - val_acc: 0.4000\n",
      "Epoch 8/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 1.0351 - acc: 0.7740Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 1.0231 - acc: 0.7801 - val_loss: 2.3486 - val_acc: 0.4250\n",
      "Epoch 9/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9961 - acc: 0.8000Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.9904 - acc: 0.8032 - val_loss: 2.3784 - val_acc: 0.3812\n",
      "Epoch 10/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9502 - acc: 0.8075Epoch 1/100\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.9379 - acc: 0.8148 - val_loss: 2.4264 - val_acc: 0.3375\n",
      "Epoch 11/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.9286 - acc: 0.8200Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.9194 - acc: 0.8264 - val_loss: 2.3842 - val_acc: 0.3250\n",
      "Epoch 12/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8689 - acc: 0.8425Epoch 1/100\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.8687 - acc: 0.8380 - val_loss: 2.3833 - val_acc: 0.3187\n",
      "Epoch 13/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8585 - acc: 0.8375Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8603 - acc: 0.8287 - val_loss: 2.3929 - val_acc: 0.3063\n",
      "Epoch 14/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8012 - acc: 0.8625Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8206 - acc: 0.8565 - val_loss: 2.3210 - val_acc: 0.3063\n",
      "Epoch 15/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8231 - acc: 0.8550Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.8137 - acc: 0.8588 - val_loss: 2.1916 - val_acc: 0.3125\n",
      "Epoch 16/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.7881 - acc: 0.8475Epoch 1/100\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.7911 - acc: 0.8449 - val_loss: 2.1197 - val_acc: 0.3250\n",
      "Epoch 17/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.7773 - acc: 0.8600Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.7920 - acc: 0.8495 - val_loss: 2.0737 - val_acc: 0.3562\n",
      "Epoch 18/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.8764 - acc: 0.8100Epoch 1/100\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.8645 - acc: 0.8194 - val_loss: 1.9553 - val_acc: 0.4062\n",
      "Epoch 19/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.7874 - acc: 0.8550Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.7783 - acc: 0.8588 - val_loss: 1.9523 - val_acc: 0.4062\n",
      "Epoch 20/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.7695 - acc: 0.8650Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.7621 - acc: 0.8704 - val_loss: 1.7228 - val_acc: 0.4812\n",
      "Epoch 21/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.7807 - acc: 0.8450Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.7805 - acc: 0.8426 - val_loss: 1.6709 - val_acc: 0.4875\n",
      "Epoch 22/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.7637 - acc: 0.8625Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.7557 - acc: 0.8657 - val_loss: 1.6990 - val_acc: 0.5250\n",
      "Epoch 23/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.7640 - acc: 0.8575Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.7727 - acc: 0.8495 - val_loss: 1.5452 - val_acc: 0.5250\n",
      "Epoch 24/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.7218 - acc: 0.8575Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.7291 - acc: 0.8542 - val_loss: 1.4337 - val_acc: 0.6062\n",
      "Epoch 25/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.7428 - acc: 0.8700Epoch 1/100\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.7340 - acc: 0.8750 - val_loss: 1.3317 - val_acc: 0.6250\n",
      "Epoch 26/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.7733 - acc: 0.8650Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.7862 - acc: 0.8611 - val_loss: 1.1472 - val_acc: 0.6875\n",
      "Epoch 27/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.7329 - acc: 0.8575Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.7244 - acc: 0.8588 - val_loss: 1.2304 - val_acc: 0.6625\n",
      "Epoch 28/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.7053 - acc: 0.8850Epoch 1/100\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.6984 - acc: 0.8866 - val_loss: 1.1433 - val_acc: 0.6938\n",
      "Epoch 29/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6972 - acc: 0.8950Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6892 - acc: 0.8981 - val_loss: 1.1033 - val_acc: 0.7125\n",
      "Epoch 30/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.7402 - acc: 0.8650Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.7262 - acc: 0.8704 - val_loss: 0.9536 - val_acc: 0.7500\n",
      "Epoch 31/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.7036 - acc: 0.9025Epoch 1/100\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.6954 - acc: 0.9005 - val_loss: 0.9565 - val_acc: 0.7688\n",
      "Epoch 32/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6728 - acc: 0.8925Epoch 1/100\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.6817 - acc: 0.8912 - val_loss: 0.9547 - val_acc: 0.7563\n",
      "Epoch 33/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.7070 - acc: 0.8875Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.7140 - acc: 0.8819 - val_loss: 0.9997 - val_acc: 0.7375\n",
      "Epoch 34/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6792 - acc: 0.8800Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6798 - acc: 0.8819 - val_loss: 0.8813 - val_acc: 0.8313\n",
      "Epoch 35/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6914 - acc: 0.8950Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6791 - acc: 0.8981 - val_loss: 0.9234 - val_acc: 0.7750\n",
      "Epoch 36/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6779 - acc: 0.8750Epoch 1/100\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.6955 - acc: 0.8704 - val_loss: 0.8198 - val_acc: 0.8313\n",
      "Epoch 37/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6553 - acc: 0.8975Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6546 - acc: 0.8958 - val_loss: 0.8385 - val_acc: 0.7812\n",
      "Epoch 38/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6865 - acc: 0.8900Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6991 - acc: 0.8843 - val_loss: 0.8844 - val_acc: 0.7750\n",
      "Epoch 39/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6979 - acc: 0.8925Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6956 - acc: 0.8935 - val_loss: 0.7634 - val_acc: 0.8313\n",
      "Epoch 40/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6786 - acc: 0.8900Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6660 - acc: 0.8935 - val_loss: 0.6968 - val_acc: 0.8625\n",
      "Epoch 41/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6383 - acc: 0.8875Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6389 - acc: 0.8889 - val_loss: 0.7110 - val_acc: 0.8687\n",
      "Epoch 42/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6334 - acc: 0.8925Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6431 - acc: 0.8866 - val_loss: 0.7640 - val_acc: 0.8313\n",
      "Epoch 43/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6680 - acc: 0.9000Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6760 - acc: 0.8935 - val_loss: 0.6584 - val_acc: 0.9125\n",
      "Epoch 44/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6682 - acc: 0.8925Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6688 - acc: 0.8912 - val_loss: 0.7393 - val_acc: 0.8813\n",
      "Epoch 45/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.7100 - acc: 0.8825Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.7247 - acc: 0.8796 - val_loss: 0.6862 - val_acc: 0.8750\n",
      "Epoch 46/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6422 - acc: 0.9050Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6361 - acc: 0.9074 - val_loss: 0.6993 - val_acc: 0.8500\n",
      "Epoch 47/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6646 - acc: 0.8725Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6544 - acc: 0.8773 - val_loss: 0.7857 - val_acc: 0.8250\n",
      "Epoch 48/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6516 - acc: 0.8900Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6440 - acc: 0.8935 - val_loss: 0.6510 - val_acc: 0.9062\n",
      "Epoch 49/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6681 - acc: 0.8850Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6602 - acc: 0.8889 - val_loss: 0.6362 - val_acc: 0.9187\n",
      "Epoch 50/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6067 - acc: 0.9200Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6028 - acc: 0.9236 - val_loss: 0.6346 - val_acc: 0.9125\n",
      "Epoch 51/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6626 - acc: 0.8825Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6476 - acc: 0.8912 - val_loss: 0.6265 - val_acc: 0.9125\n",
      "Epoch 52/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6413 - acc: 0.8925Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6543 - acc: 0.8866 - val_loss: 0.6499 - val_acc: 0.9000\n",
      "Epoch 53/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5993 - acc: 0.9150Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6097 - acc: 0.9051 - val_loss: 0.6856 - val_acc: 0.9062\n",
      "Epoch 54/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6090 - acc: 0.9225Epoch 1/100\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.6079 - acc: 0.9213 - val_loss: 0.6135 - val_acc: 0.9312\n",
      "Epoch 55/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6125 - acc: 0.9014Epoch 1/100\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.6317 - acc: 0.8981 - val_loss: 0.6213 - val_acc: 0.9062\n",
      "Epoch 56/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6328 - acc: 0.8900Epoch 1/100\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.6316 - acc: 0.8912 - val_loss: 0.7009 - val_acc: 0.8750\n",
      "Epoch 57/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6235 - acc: 0.8950Epoch 1/100\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.6298 - acc: 0.8889 - val_loss: 0.7923 - val_acc: 0.8438\n",
      "Epoch 58/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6274 - acc: 0.9150Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6263 - acc: 0.9144 - val_loss: 0.6579 - val_acc: 0.9125\n",
      "Epoch 59/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6563 - acc: 0.9000Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6427 - acc: 0.9074 - val_loss: 0.6858 - val_acc: 0.8750\n",
      "Epoch 60/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6284 - acc: 0.8975Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6165 - acc: 0.9028 - val_loss: 0.6495 - val_acc: 0.8875\n",
      "Epoch 61/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6707 - acc: 0.8875Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6616 - acc: 0.8935 - val_loss: 0.6156 - val_acc: 0.9125\n",
      "Epoch 62/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6243 - acc: 0.8900Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6309 - acc: 0.8843 - val_loss: 0.6467 - val_acc: 0.9062\n",
      "Epoch 63/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6078 - acc: 0.9225Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6102 - acc: 0.9213 - val_loss: 0.5885 - val_acc: 0.9000\n",
      "Epoch 64/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5527 - acc: 0.9300Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5524 - acc: 0.9259 - val_loss: 0.5926 - val_acc: 0.9187\n",
      "Epoch 65/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5869 - acc: 0.9275Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5873 - acc: 0.9236 - val_loss: 0.6501 - val_acc: 0.8750\n",
      "Epoch 66/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5811 - acc: 0.9225Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5766 - acc: 0.9236 - val_loss: 0.6546 - val_acc: 0.8687\n",
      "Epoch 67/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6116 - acc: 0.8900Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6133 - acc: 0.8912 - val_loss: 0.5884 - val_acc: 0.9125\n",
      "Epoch 68/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5934 - acc: 0.9135Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5912 - acc: 0.9120 - val_loss: 0.7043 - val_acc: 0.8562\n",
      "Epoch 69/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6093 - acc: 0.9100Epoch 1/100\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.6059 - acc: 0.9120 - val_loss: 0.5679 - val_acc: 0.9062\n",
      "Epoch 70/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6027 - acc: 0.9125Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5928 - acc: 0.9167 - val_loss: 0.6346 - val_acc: 0.9062\n",
      "Epoch 71/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6276 - acc: 0.8870Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6242 - acc: 0.8889 - val_loss: 0.5963 - val_acc: 0.9000\n",
      "Epoch 72/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5917 - acc: 0.9135Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6037 - acc: 0.9074 - val_loss: 0.7592 - val_acc: 0.8313\n",
      "Epoch 73/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.6075 - acc: 0.9100Epoch 1/100\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.6033 - acc: 0.9120 - val_loss: 0.6500 - val_acc: 0.9000\n",
      "Epoch 74/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5610 - acc: 0.9450Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5633 - acc: 0.9421 - val_loss: 0.6260 - val_acc: 0.9125\n",
      "Epoch 75/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5811 - acc: 0.9300Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5845 - acc: 0.9259 - val_loss: 0.6796 - val_acc: 0.8938\n",
      "Epoch 76/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5930 - acc: 0.9225Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5826 - acc: 0.9282 - val_loss: 0.7932 - val_acc: 0.8313\n",
      "Epoch 77/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5575 - acc: 0.9150Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5510 - acc: 0.9190 - val_loss: 0.6662 - val_acc: 0.8875\n",
      "Epoch 78/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5687 - acc: 0.9125Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5674 - acc: 0.9167 - val_loss: 0.5930 - val_acc: 0.9062\n",
      "Epoch 79/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5800 - acc: 0.9225Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5798 - acc: 0.9236 - val_loss: 0.5648 - val_acc: 0.9312\n",
      "Epoch 80/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5512 - acc: 0.9350Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5492 - acc: 0.9352 - val_loss: 0.6068 - val_acc: 0.8875\n",
      "Epoch 81/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5919 - acc: 0.9250Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5898 - acc: 0.9259 - val_loss: 0.5870 - val_acc: 0.9000\n",
      "Epoch 82/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5880 - acc: 0.9050Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.6157 - acc: 0.8958 - val_loss: 0.6718 - val_acc: 0.8625\n",
      "Epoch 83/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5602 - acc: 0.9375Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5508 - acc: 0.9421 - val_loss: 0.5728 - val_acc: 0.8875\n",
      "Epoch 84/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5367 - acc: 0.9300Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5489 - acc: 0.9236 - val_loss: 0.6807 - val_acc: 0.8750\n",
      "Epoch 85/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5537 - acc: 0.9250Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5492 - acc: 0.9306 - val_loss: 0.5660 - val_acc: 0.9062\n",
      "Epoch 86/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5477 - acc: 0.9350Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5546 - acc: 0.9306 - val_loss: 0.5617 - val_acc: 0.9250\n",
      "Epoch 87/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5694 - acc: 0.9250Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5778 - acc: 0.9213 - val_loss: 0.5761 - val_acc: 0.9062\n",
      "Epoch 88/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5359 - acc: 0.9175Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5479 - acc: 0.9144 - val_loss: 0.6452 - val_acc: 0.8750\n",
      "Epoch 89/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5687 - acc: 0.9225Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5630 - acc: 0.9259 - val_loss: 0.5866 - val_acc: 0.9187\n",
      "Epoch 90/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5607 - acc: 0.9250Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5597 - acc: 0.9236 - val_loss: 0.5828 - val_acc: 0.9062\n",
      "Epoch 91/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5355 - acc: 0.9325Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5357 - acc: 0.9329 - val_loss: 0.7707 - val_acc: 0.8562\n",
      "Epoch 92/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5489 - acc: 0.9500Epoch 1/100\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.5522 - acc: 0.9468 - val_loss: 0.7150 - val_acc: 0.8562\n",
      "Epoch 93/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5743 - acc: 0.9200Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5672 - acc: 0.9213 - val_loss: 0.6658 - val_acc: 0.8687\n",
      "Epoch 94/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5404 - acc: 0.9175Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5448 - acc: 0.9167 - val_loss: 0.6241 - val_acc: 0.8875\n",
      "Epoch 95/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5303 - acc: 0.9400Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5295 - acc: 0.9421 - val_loss: 0.5474 - val_acc: 0.9375\n",
      "Epoch 96/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5453 - acc: 0.9300Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5412 - acc: 0.9306 - val_loss: 0.5732 - val_acc: 0.9250\n",
      "Epoch 97/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5295 - acc: 0.9375Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5265 - acc: 0.9398 - val_loss: 0.5846 - val_acc: 0.9062\n",
      "Epoch 98/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5511 - acc: 0.9300Epoch 1/100\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.5448 - acc: 0.9329 - val_loss: 0.5270 - val_acc: 0.9438\n",
      "Epoch 99/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5014 - acc: 0.9600Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5171 - acc: 0.9491 - val_loss: 0.5490 - val_acc: 0.9312\n",
      "Epoch 100/100\n",
      "13/14 [==========================>...] - ETA: 0s - loss: 0.5217 - acc: 0.9300Epoch 1/100\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.5194 - acc: 0.9306 - val_loss: 0.5671 - val_acc: 0.9125\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Main function\n",
    "def main(n, framework):\n",
    "    # layers = 6n+2\n",
    "    net = ResNet(n, framework, nb_epochs=1)\n",
    "    base_dir = '/content/drive/My Drive/B.E PROJECT/CNN CROP/data/disease/input'\n",
    "\n",
    "    TRAIN_PATH = os.path.join(base_dir, 'Training')\n",
    "    VALIDATION_PATH = os.path.join(base_dir, 'Validation')\n",
    "    net.train(TRAIN_PATH, VALIDATION_PATH)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(3, \"keras_tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "RsyPc3-ir8YW",
    "outputId": "36170639-1952-4b31-dbc0-5586e4bafc1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cotton_disease-resnet50E44L.h5  'logsRN-3(100E 44L)'   sample_data\n",
      " drive\t\t\t\t  ResNet.png\n"
     ]
    }
   ],
   "source": [
    "  !ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "8cnyYNFOS3rF",
    "outputId": "fa08cdfe-bcec-47f7-9a72-fad7e5fdb223"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: content/logsRN-20L-100E/ (stored 0%)\n",
      "updating: content/logsRN-20L-100E/1572362288.7122812/ (stored 0%)\n",
      "updating: content/logsRN-20L-100E/1572362288.7122812/events.out.tfevents.1572362294.663fdcb55619 (deflated 91%)\n",
      "updating: content/logsRN-20L-100E/1572362288.7122812/events.out.tfevents.1572362346.663fdcb55619.profile-empty (deflated 8%)\n",
      "updating: content/logsRN-20L-100E/1572362288.7122812/plugins/ (stored 0%)\n",
      "updating: content/logsRN-20L-100E/1572362288.7122812/plugins/profile/ (stored 0%)\n",
      "updating: content/logsRN-20L-100E/1572362288.7122812/plugins/profile/2019-10-29_15-19-06/ (stored 0%)\n",
      "updating: content/logsRN-20L-100E/1572362288.7122812/plugins/profile/2019-10-29_15-19-06/local.trace (deflated 96%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r \"/content/resnet20L100E.zip\" \"/content/logsRN-20L-100E/\"\n",
    "from google.colab import files\n",
    "files.download(\"/content/resnet20L100E.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OaqTtxb7S9lY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "batch_holder = np.zeros((19, 300,300, 3))\n",
    "    \n",
    "model = load_model('cotton_disease-resnet-20L-100E.h5')\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "img_dir = '../../CNN_Data/Test'\n",
    "\n",
    "for i,img in enumerate(os.listdir(img_dir)[1:]):\n",
    "  img = image.load_img(os.path.join(img_dir,img), target_size=(300, 300))\n",
    "  batch_holder[i, :] = img\n",
    "\n",
    "result= model.predict_classes(batch_holder)\n",
    " \n",
    "fig = plt.figure(figsize=(20, 20))\n",
    " \n",
    "for i,img in enumerate(batch_holder):\n",
    "  fig.add_subplot(4,5, i+1)\n",
    "  plt.title(result[i])\n",
    "  plt.imshow(img/256.)\n",
    "  \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ResNet-20L-100E.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
